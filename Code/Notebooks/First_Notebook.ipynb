{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z8/jwxsd17n57lblqk5c_v8fttc0000gn/T/ipykernel_14456/2624026049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "from tqdm import tqdm\n",
    "from scipy.special import erf\n",
    "import scipy.stats\n",
    "\n",
    "from dmipy.core.acquisition_scheme import acquisition_scheme_from_bvalues\n",
    "from dmipy.core.modeling_framework import MultiCompartmentSphericalMeanModel\n",
    "from dmipy.signal_models import sphere_models, cylinder_models, gaussian_models\n",
    "\n",
    "from scipy.io import savemat\n",
    "start_time = time.time()\n",
    "# simulate data according to verdict model - there is a function for each of the three compartments\n",
    "# when you do it for bbb-fexi, this will change\n",
    "\n",
    "def sphere(r):\n",
    "\n",
    "    SPHERE_TRASCENDENTAL_ROOTS = np.r_[\n",
    "        # 0.,\n",
    "        2.081575978, 5.940369990, 9.205840145,\n",
    "        12.40444502, 15.57923641, 18.74264558, 21.89969648,\n",
    "        25.05282528, 28.20336100, 31.35209173, 34.49951492,\n",
    "        37.64596032, 40.79165523, 43.93676147, 47.08139741,\n",
    "        50.22565165, 53.36959180, 56.51327045, 59.65672900,\n",
    "        62.80000055, 65.94311190, 69.08608495, 72.22893775,\n",
    "        75.37168540, 78.51434055, 81.65691380, 84.79941440,\n",
    "        87.94185005, 91.08422750, 94.22655255, 97.36883035,\n",
    "        100.5110653, 103.6532613, 106.7954217, 109.9375497,\n",
    "        113.0796480, 116.2217188, 119.3637645, 122.5057870,\n",
    "        125.6477880, 128.7897690, 131.9317315, 135.0736768,\n",
    "        138.2156061, 141.3575204, 144.4994207, 147.6413080,\n",
    "        150.7831829, 153.9250463, 157.0668989, 160.2087413,\n",
    "        163.3505741, 166.4923978, 169.6342129, 172.7760200,\n",
    "        175.9178194, 179.0596116, 182.2013968, 185.3431756,\n",
    "        188.4849481, 191.6267147, 194.7684757, 197.9102314,\n",
    "        201.0519820, 204.1937277, 207.3354688, 210.4772054,\n",
    "        213.6189378, 216.7606662, 219.9023907, 223.0441114,\n",
    "        226.1858287, 229.3275425, 232.4692530, 235.6109603,\n",
    "        238.7526647, 241.8943662, 245.0360648, 248.1777608,\n",
    "        251.3194542, 254.4611451, 257.6028336, 260.7445198,\n",
    "        263.8862038, 267.0278856, 270.1695654, 273.3112431,\n",
    "        276.4529189, 279.5945929, 282.7362650, 285.8779354,\n",
    "        289.0196041, 292.1612712, 295.3029367, 298.4446006,\n",
    "        301.5862631, 304.7279241, 307.8695837, 311.0112420,\n",
    "        314.1528990\n",
    "    ]\n",
    "\n",
    "    D = 2\n",
    "    gamma = 2.67e2\n",
    "    radius = r\n",
    "\n",
    "    b_values = np.array([1e-6, 0.090, 1e-6, 0.500, 1e-6, 1.5, 1e-6, 2, 1e-6, 3])\n",
    "    Delta = np.array([23.8, 23.8, 23.8, 31.3, 23.8, 43.8, 23.8, 34.3, 23.8, 38.8])\n",
    "    delta = np.array([3.9, 3.9, 3.9, 11.4, 3.9, 23.9, 3.9, 14.4, 3.9, 18.9])\n",
    "\n",
    "    gradient_strength = np.array([np.sqrt(b_values[i])/(gamma*delta[i]*np.sqrt(Delta[i]-delta[i]/3)) for i,_ in enumerate(b_values)])\n",
    "\n",
    "    alpha = SPHERE_TRASCENDENTAL_ROOTS / radius\n",
    "    alpha2 = alpha ** 2\n",
    "    alpha2D = alpha2 * D\n",
    "\n",
    "    first_factor = -2 * (gamma * gradient_strength) ** 2 / D\n",
    "    \n",
    "    summands = np.zeros((len(SPHERE_TRASCENDENTAL_ROOTS),len(b_values)))\n",
    "    for i,_ in enumerate(delta):\n",
    "        summands[:,i] = (\n",
    "            alpha ** (-4) / (alpha2 * radius ** 2 - 2) *\n",
    "            (\n",
    "                2 * delta[i] - (\n",
    "                    2 +\n",
    "                    np.exp(-alpha2D * (Delta[i] - delta[i])) -\n",
    "                    2 * np.exp(-alpha2D * delta[i]) -\n",
    "                    2 * np.exp(-alpha2D * Delta[i]) +\n",
    "                    np.exp(-alpha2D * (Delta[i] + delta[i]))\n",
    "                ) / (alpha2D)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    E = np.exp(\n",
    "        first_factor *\n",
    "        summands.sum()\n",
    "    )\n",
    "\n",
    "    return E\n",
    "\n",
    "def ball(d):\n",
    "\n",
    "    bvals = np.array([1e-6, 0.090, 1e-6, 0.500, 1e-6, 1.5, 1e-6, 2, 1e-6, 3])\n",
    "    E_ball = np.exp(-bvals * d)\n",
    "    \n",
    "    return E_ball\n",
    "\n",
    "def astrosticks(l):\n",
    "\n",
    "    bvals = np.array([1e-6, 0.090, 1e-6, 0.500, 1e-6, 1.5, 1e-6, 2, 1e-6, 3])\n",
    "    lambda_par = l\n",
    "    E_mean = np.ones_like(bvals)\n",
    "    E_mean = ((np.sqrt(np.pi) * erf(np.sqrt(bvals * lambda_par))) /\n",
    "                (2 * np.sqrt(bvals * lambda_par)))\n",
    "\n",
    "    return E_mean\n",
    "\n",
    "\n",
    "nvox = 50000 # number of voxels to simulate Try with 1000\n",
    "radii = np.random.uniform(0.001,15,nvox) # free parameter - cell radius\n",
    "dees = np.random.uniform(0.5,3,nvox) # free parameter - EES diffusivity\n",
    "lambdapar = np.repeat(2,nvox) # fixed parameter\n",
    "E_stick = np.array([astrosticks(l) for l in lambdapar]) \n",
    "E_ball = np.array([ball(d) for d in dees])\n",
    "E_sphere = np.array([sphere(r) for r in radii])\n",
    "fic = np.expand_dims(np.random.uniform(0.001, 0.999, nvox), axis=1) # free parameter - IC volume fraction\n",
    "fees = np.expand_dims(np.random.uniform(0.001, 0.999, nvox), axis=1) # free parameter - EES volume fraction\n",
    "fvasc = 1 - fic - fees # calculate VASC volume fraction\n",
    "fvasc = fvasc/(fic + fees + fvasc)\n",
    "A = fvasc\n",
    "normA = A - min(A)\n",
    "fvasc = 0.2 * (normA/max(normA)) # constraining fvasc to be realistic for prostate tissue (under 0.2)\n",
    "fic = fic/(fic + fees + fvasc)\n",
    "fees = fees/(fic + fees + fvasc)\n",
    "E_vox = fees*E_ball + fic*E_sphere + fvasc*E_stick\n",
    "E_vox_real = E_vox + np.random.normal(scale=0.02, size=np.shape(E_vox)) # adding rician noise, snr = 50\n",
    "E_vox_imag = np.random.normal(scale=0.02, size=np.shape(E_vox))\n",
    "E_vox = np.sqrt(E_vox_real**2 + E_vox_imag**2) # these are the simulated signals\n",
    "\n",
    "print(\"the code ran until the first breakpoint\")\n",
    "\n",
    "'''\n",
    "\n",
    "## this section will be useful when you want to compare it to NLLS fitting, i'm commenting it out for now\n",
    "\n",
    "b_values = np.array([1e-6, 90, 1e-6, 500, 1e-6, 1500, 1e-6, 2000, 1e-6, 3000])\n",
    "bvaluesSI = np.array([i * 1e6 for i in b_values])\n",
    "Delta = np.array([0.0238, 0.0238, 0.0238, 0.0313, 0.0238, 0.0438, 0.0238, 0.0343, 0.0238, 0.0388])\n",
    "delta = np.array([0.0039, 0.0039, 0.0039, 0.0114, 0.0039, 0.0239, 0.0039, 0.0144, 0.0039, 0.0189])\n",
    "gradient_directions = np.loadtxt('./verdict_graddirs.txt', delimiter=',')\n",
    "acq_scheme = acquisition_scheme_from_bvalues(bvaluesSI, gradient_directions, delta, Delta)\n",
    "\n",
    "spheresim = sphere_models.S4SphereGaussianPhaseApproximation(diffusion_constant=2e-9)\n",
    "ballsim = gaussian_models.G1Ball()\n",
    "sticksim = cylinder_models.C1Stick(lambda_par=2e-9)\n",
    "astro = sticksim.spherical_mean(acq_scheme)\n",
    "\n",
    "from dmipy.core.modeling_framework import MultiCompartmentModel\n",
    "verdict_mod = MultiCompartmentModel(models=[spheresim, ballsim, sticksim])\n",
    "verdict_mod.set_parameter_optimization_bounds('G1Ball_1_lambda_iso', [0.5e-9, 3e-9])\n",
    "verdict_mod.set_parameter_optimization_bounds('partial_volume_0', [0.001, 0.999])\n",
    "verdict_mod.set_parameter_optimization_bounds('partial_volume_1', [0.001, 0.999])\n",
    "verdict_mod.set_parameter_optimization_bounds('partial_volume_1', [0.001, 0.199])\n",
    "verdict_mod.set_parameter_optimization_bounds('G1Ball_1_lambda_iso', [0.5e-9, 3e-9])\n",
    "\n",
    "\n",
    "res = verdict_mod.fit(acq_scheme, E_vox)\n",
    "f_ic = res.fitted_parameters['partial_volume_0']\n",
    "f_ees = res.fitted_parameters['partial_volume_1']\n",
    "f_vasc = res.fitted_parameters['partial_volume_2']\n",
    "r = res.fitted_parameters['S4SphereGaussianPhaseApproximation_1_diameter']/2\n",
    "d_ees = res.fitted_parameters['G1Ball_1_lambda_iso']\n",
    "'''\n",
    "\n",
    "class Net(nn.Module): # this is the neural network\n",
    "\n",
    "    def __init__(self, b_values, Delta, delta, gradient_strength, nparams):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.b_values = b_values\n",
    "        self.Delta = Delta\n",
    "        self.delta = delta\n",
    "        self.gradient_strength = gradient_strength\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(3): # 3 fully connected hidden layers\n",
    "            self.layers.extend([nn.Linear(len(b_values), len(b_values)), nn.PReLU()])\n",
    "        self.encoder = nn.Sequential(*self.layers, nn.Linear(len(b_values), nparams))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        params = torch.nn.functional.softplus(self.encoder(X))\n",
    "        f_ic = torch.clamp(params[:,0].unsqueeze(1), min=0.001, max=0.999) # parameter constraints\n",
    "        f_ees = torch.clamp(params[:,1].unsqueeze(1), min=0.001, max=0.999)\n",
    "        r = torch.clamp(params[:,2].unsqueeze(1), min=0.001, max=14.999)\n",
    "        d_ees = torch.clamp(params[:,3].unsqueeze(1), min=0.5, max=3)\n",
    "\n",
    "        SPHERE_TRASCENDENTAL_ROOTS = np.r_[\n",
    "        # 0.,\n",
    "        2.081575978, 5.940369990, 9.205840145,\n",
    "        12.40444502, 15.57923641, 18.74264558, 21.89969648,\n",
    "        25.05282528, 28.20336100, 31.35209173, 34.49951492,\n",
    "        37.64596032, 40.79165523, 43.93676147, 47.08139741,\n",
    "        50.22565165, 53.36959180, 56.51327045, 59.65672900,\n",
    "        62.80000055, 65.94311190, 69.08608495, 72.22893775,\n",
    "        75.37168540, 78.51434055, 81.65691380, 84.79941440,\n",
    "        87.94185005, 91.08422750, 94.22655255, 97.36883035,\n",
    "        100.5110653, 103.6532613, 106.7954217, 109.9375497,\n",
    "        113.0796480, 116.2217188, 119.3637645, 122.5057870,\n",
    "        125.6477880, 128.7897690, 131.9317315, 135.0736768,\n",
    "        138.2156061, 141.3575204, 144.4994207, 147.6413080,\n",
    "        150.7831829, 153.9250463, 157.0668989, 160.2087413,\n",
    "        163.3505741, 166.4923978, 169.6342129, 172.7760200,\n",
    "        175.9178194, 179.0596116, 182.2013968, 185.3431756,\n",
    "        188.4849481, 191.6267147, 194.7684757, 197.9102314,\n",
    "        201.0519820, 204.1937277, 207.3354688, 210.4772054,\n",
    "        213.6189378, 216.7606662, 219.9023907, 223.0441114,\n",
    "        226.1858287, 229.3275425, 232.4692530, 235.6109603,\n",
    "        238.7526647, 241.8943662, 245.0360648, 248.1777608,\n",
    "        251.3194542, 254.4611451, 257.6028336, 260.7445198,\n",
    "        263.8862038, 267.0278856, 270.1695654, 273.3112431,\n",
    "        276.4529189, 279.5945929, 282.7362650, 285.8779354,\n",
    "        289.0196041, 292.1612712, 295.3029367, 298.4446006,\n",
    "        301.5862631, 304.7279241, 307.8695837, 311.0112420,\n",
    "        314.1528990\n",
    "        ]\n",
    "        \n",
    "        alpha = torch.FloatTensor(SPHERE_TRASCENDENTAL_ROOTS) / (r)\n",
    "        alpha2 = alpha ** 2\n",
    "        alpha2D = alpha2 * 2\n",
    "        alpha = alpha.unsqueeze(1)\n",
    "        alpha2 = alpha2.unsqueeze(1)\n",
    "        alpha2D = alpha2D.unsqueeze(1)\n",
    "\n",
    "        gamma = 2.675987e2\n",
    "        first_factor = -2*(gamma*self.gradient_strength)**2 / 2\n",
    "\n",
    "        delta = self.delta.unsqueeze(0).unsqueeze(2)\n",
    "        Delta = self.Delta.unsqueeze(0).unsqueeze(2)\n",
    "        \n",
    "        summands = (alpha ** (-4) / (alpha2 * (r.unsqueeze(2))**2 - 2) * (\n",
    "                            2 * delta - (\n",
    "                            2 +\n",
    "                            torch.exp(-alpha2D * (Delta - delta)) -\n",
    "                            2 * torch.exp(-alpha2D * delta) -\n",
    "                            2 * torch.exp(-alpha2D * Delta) +\n",
    "                            torch.exp(-alpha2D * (Delta + delta))\n",
    "                        ) / (alpha2D)\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # this is where you will eventually need to tweak the network to be bbb-fexi rather than verdict\n",
    "\n",
    "        xi = (1 - f_ic - f_ees) * ((np.sqrt(np.pi) * torch.erf(np.sqrt(self.b_values * 2))) /\n",
    "                (2 * np.sqrt(self.b_values * 2)))\n",
    "        xii = f_ic * torch.exp(torch.FloatTensor(first_factor) * torch.sum(summands, 2))\n",
    "        xiii = f_ees * torch.exp(-self.b_values * d_ees)        \n",
    "        X = xi + xii + xiii\n",
    "\n",
    "        return X, f_ic, f_ees, r, d_ees\n",
    "\n",
    "print(\"this is the second breakpoint\")\n",
    "\n",
    "# define network\n",
    "nparams = 4\n",
    "b_values = torch.FloatTensor([1e-6, 0.090, 1e-6, 0.500, 1e-6, 1.5, 1e-6, 2, 1e-6, 3])\n",
    "Delta = torch.FloatTensor([23.8, 23.8, 23.8, 31.3, 23.8, 43.8, 23.8, 34.3, 23.8, 38.8])\n",
    "delta = torch.FloatTensor([3.9, 3.9, 3.9, 11.4, 3.9, 23.9, 3.9, 14.4, 3.9, 18.9])\n",
    "gamma = 2.67e2\n",
    "gradient_strength = torch.FloatTensor([np.sqrt(b_values[i])/(gamma*delta[i]*np.sqrt(Delta[i]-delta[i]/3)) for i,_ in enumerate(b_values)])\n",
    "net = Net(b_values, Delta, delta, gradient_strength, nparams)\n",
    "\n",
    "#create batch queues for data\n",
    "batch_size = 128\n",
    "num_batches = len(E_vox) // batch_size\n",
    "trainloader = utils.DataLoader(torch.from_numpy(E_vox.astype(np.float32)),\n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = True,\n",
    "                                num_workers = 0, #was 2 previously\n",
    "                                drop_last = True)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "# best loss\n",
    "best = 1e16\n",
    "num_bad_epochs = 0\n",
    "patience = 10\n",
    "\n",
    "print(\"third breakpoint\")\n",
    "\n",
    "# train\n",
    "for epoch in range(10000): \n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(\"epoch: {}; bad epochs: {}\".format(epoch, num_bad_epochs))\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, X_batch in enumerate(tqdm(trainloader), 0):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        X_pred, f_ic_pred, f_ees_pred, r_pred, d_ees_pred = net(X_batch)\n",
    "        loss = criterion(X_pred, X_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "    print(\"loss: {}\".format(running_loss))\n",
    "    # early stopping\n",
    "    if running_loss < best:\n",
    "        print(\"####################### saving good model #######################\")\n",
    "        final_model = net.state_dict()\n",
    "        best = running_loss\n",
    "        num_bad_epochs = 0\n",
    "    else:\n",
    "        num_bad_epochs = num_bad_epochs + 1\n",
    "        if num_bad_epochs == patience:\n",
    "            print(\"done, best loss: {}\".format(best))\n",
    "            break\n",
    "print(\"done\")\n",
    "\n",
    "net.load_state_dict(final_model)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    X_real_pred, f_ic, f_ees, r, d_ees = net(torch.from_numpy(E_vox.astype(np.float32)))\n",
    "\n",
    "f_vasc = 1 - f_ic - f_ees\n",
    "\n",
    "f_vasc = f_vasc/(f_ic + f_ees + f_vasc)\n",
    "A = f_vasc\n",
    "normA = A - min(A)\n",
    "f_vasc = 0.2 * (normA/max(normA))\n",
    "f_ic = f_ic/(f_ic + f_ees + f_vasc)\n",
    "f_ees = f_ees/(f_ic + f_ees + f_vasc)\n",
    "\n",
    "print(\"fourth breakpoint\")\n",
    "\n",
    "# check predicted signal against simulated signal\n",
    "\n",
    "plt.scatter(b_values, E_vox[0,:], label='simulated')\n",
    "plt.scatter(b_values, X_real_pred[0,:], label='predicted')\n",
    "plt.legend()\n",
    "\n",
    "# plot scatter plots to analyse correlation of predicted free params against ground truth\n",
    "\n",
    "param = [fic, fees, fvasc, radii, dees]\n",
    "param_f = [f_ic, f_ees, f_vasc, r, d_ees]\n",
    "param_name = ['fIC', 'fEES', 'fVASC', 'R', 'dEES']\n",
    "rvals = []\n",
    "\n",
    "for i,_ in enumerate(param):\n",
    "    plt.rcParams['font.size'] = '16'\n",
    "    plt.scatter(param[i], param_f[i], s=2, c='navy')\n",
    "    plt.xlabel(param_name[i] + ' Ground Truth')\n",
    "    plt.ylabel(param_name[i] + ' Prediction')\n",
    "    rvals.append(scipy.stats.pearsonr(np.squeeze(param[i]), np.squeeze(param_f[i])))\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "\n",
    "print(rvals)\n",
    "\n",
    "\n",
    "print(\"fifth breakpoint\")\n",
    "\n",
    "## bias-variance calculations\n",
    "\n",
    "bias_fic = torch.mean(f_ic - fic)\n",
    "bias_fees = torch.mean(f_ees - fees)\n",
    "bias_r = torch.mean(r - radii)\n",
    "bias_dees = torch.mean(d_ees - dees)\n",
    "\n",
    "var_fic = torch.mean((f_ic - torch.mean(f_ic))**2)\n",
    "var_fees = torch.mean((f_ees - torch.mean(f_ees))**2)\n",
    "var_r = torch.mean((r - torch.mean(r))**2)\n",
    "var_dees = torch.mean((d_ees - torch.mean(d_ees))**2)\n",
    "\n",
    "mse_fic = torch.mean((f_ic - fic)**2)\n",
    "mse_fees = torch.mean((f_ees - fees)**2)\n",
    "mse_r = torch.mean((r - radii)**2)\n",
    "mse_dees = torch.mean((d_ees - dees)**2)\n",
    "\n",
    "print(bias_fic, bias_fees, bias_r, bias_dees)\n",
    "print(var_fic, var_fees, var_r, var_dees)\n",
    "print(mse_fic, mse_fees, mse_r, mse_dees)\n",
    "\n",
    "\n",
    "r = r*1e6\n",
    "d_ees = d_ees*1e9\n",
    "'''\n",
    "bias_fic = np.mean(f_ic - fic)\n",
    "bias_fees = np.mean(f_ees - fees)\n",
    "bias_r = np.mean(r - radii)\n",
    "bias_dees = np.mean(d_ees - dees)\n",
    "\n",
    "var_fic = np.mean((f_ic - np.mean(f_ic))**2)\n",
    "var_fees = np.mean((f_ees - np.mean(f_ees))**2)\n",
    "var_r = np.mean((r - np.mean(r))**2)\n",
    "var_dees = np.mean((d_ees - np.mean(d_ees))**2)\n",
    "\n",
    "mse_fic = np.mean((f_ic - fic)**2)\n",
    "mse_fees = np.mean((f_ees - fees)**2)\n",
    "mse_r = np.mean((r - radii)**2)\n",
    "mse_dees = np.mean((d_ees - dees)**2)\n",
    "\n",
    "print(bias_fic, bias_fees, bias_r, bias_dees)\n",
    "print(var_fic, var_fees, var_r, var_dees)\n",
    "print(mse_fic, mse_fees, mse_r, mse_dees)'''\n",
    "print(\"sixth breakpoint\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b674b819d8671980ca5a3fbbf6ef3960c78dfe46bc6c386a332b1e33b658c9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
