{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/envs/project/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from scipy.special import erf\n",
    "import scipy.stats\n",
    "\n",
    "from dmipy.core.acquisition_scheme import acquisition_scheme_from_bvalues\n",
    "from dmipy.core.modeling_framework import MultiCompartmentSphericalMeanModel\n",
    "from dmipy.signal_models import sphere_models, cylinder_models, gaussian_models\n",
    "\n",
    "from scipy.io import savemat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_sig_np(bf,be,tm,adc,sigma,axr,nvox):\n",
    "    \n",
    "    be_tiled = np.tile(be,(nvox,1))\n",
    "    bf_tiled = np.tile(bf,(nvox,1))\n",
    "    tm_tiled = np.tile(tm,(nvox,1))\n",
    "\n",
    "    adc_tiled = np.transpose(np.tile(adc,(np.size(tm),1)))\n",
    "    sigma_tiled = np.transpose(np.tile(sigma,(np.size(tm),1)))\n",
    "    axr_tiled = np.transpose(np.tile(axr,(np.size(tm),1)))\n",
    "\n",
    "    tm_tiled[(tm_tiled == np.min(tm_tiled)) & (bf_tiled == 0)] = np.inf\n",
    "\n",
    "    adc_prime_tiled = adc_tiled * (1 - sigma_tiled* np.exp(-tm_tiled*axr_tiled))\n",
    "    normalised_signal_tiled = np.exp(-adc_prime_tiled * be_tiled)\n",
    "\n",
    "    return normalised_signal_tiled, adc_prime_tiled\n",
    "\n",
    "def sim_sig_np_1_vox(bf,be,tm,adc,sigma,axr):\n",
    "\n",
    "    adc_tiled = np.transpose(np.tile(adc,(np.size(tm),1)))\n",
    "    sigma_tiled = np.transpose(np.tile(sigma,(np.size(tm),1)))\n",
    "    axr_tiled = np.transpose(np.tile(axr,(np.size(tm),1)))\n",
    "\n",
    "    tm[(tm == np.min(tm)) & (bf == 0)] = np.inf\n",
    "\n",
    "    adc_prime = adc_tiled * (1 - sigma_tiled* np.exp(-tm*axr_tiled))\n",
    "    normalised_signal = np.exp(-adc_prime * be)\n",
    "    \n",
    "    return normalised_signal, adc_prime\n",
    "\n",
    "def sim_sig_pytorch_new(bf,be,tm,adc,sigma,axr,nvox):\n",
    "    \n",
    "    be_tiled = torch.tile(be,(nvox,1))\n",
    "    bf_tiled = torch.tile(bf,(nvox,1))\n",
    "    tm_tiled = torch.tile(tm,(nvox,1))\n",
    "\n",
    "    \n",
    "    \"\"\"adc_tiled = torch.tile(adc,(tm.shape[0],1)).t()\n",
    "    sigma_tiled = torch.tile(sigma,(tm.shape[0],1)).t()\n",
    "    axr_tiled = torch.tile(axr,(tm.shape[0],1)).t()\"\"\"\n",
    "\n",
    "    adc_tiled = torch.tile(adc,(1,tm.shape[0]))\n",
    "    sigma_tiled = torch.tile(sigma,(1,tm.shape[0]))\n",
    "    axr_tiled = torch.tile(axr,(1,tm.shape[0]))\n",
    "\n",
    "    tm_tiled[(tm_tiled == torch.min(tm_tiled)) & (bf_tiled == 0)] = torch.inf\n",
    "\n",
    "    \"\"\"print(\"be: \", be_tiled.shape)\n",
    "    print(\"bf: \", bf_tiled.shape)\n",
    "    print(\"tm: \", tm_tiled.shape)\n",
    "    print(\"adc: \", adc_tiled.shape)\n",
    "    print(\"sigma: \", sigma_tiled.shape)\n",
    "    print(\"axr: \", axr_tiled.shape)\"\"\"\n",
    "\n",
    "\n",
    "    adc_prime_tiled = adc_tiled * (1 - sigma_tiled*torch.exp(-tm_tiled*axr_tiled))\n",
    "    normalised_signal_tiled = torch.exp(-adc_prime_tiled * be_tiled)\n",
    "    \n",
    "    return normalised_signal_tiled, adc_prime_tiled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvox = 1000 # number of voxels to simulate\n",
    "\n",
    "bf = np.array([0, 0, 250, 250, 250, 250, 250, 250]) * 1e-3   # filter b-values [ms/um2]\n",
    "be = np.array([0, 250, 0, 250, 0, 250, 0, 250]) * 1e-3       # encoding b-values [ms/um2]\n",
    "tm = np.array([20, 20, 20, 20, 200, 200, 400, 400], dtype=np.float32) * 1e-3 # mixing time [s]\n",
    "\n",
    "adc_lb = 0.1        #[um2/ms]\n",
    "adc_ub = 3.5        #[um2/ms]\n",
    "sig_lb = 0          #[a.u.]\n",
    "sig_ub = 1          #[a.u.]\n",
    "axr_lb = 0.1        #[s-1]\n",
    "\n",
    "axr_lb = 1        #[s-1]\n",
    "\n",
    "axr_ub = 20         #[s-1]\n",
    "\n",
    "#consider doing in si units\n",
    "\n",
    "limits = np.array([[adc_lb, adc_ub], [sig_lb, sig_ub] , [axr_lb, axr_ub]])\n",
    "\n",
    "adc_init = (adc_lb + adc_ub) / 2 #[um2/ms]\n",
    "sig_init = (sig_lb + sig_ub) / 2 #[a.u.]\n",
    "axr_init = (axr_lb + axr_ub) / 2 #[ms-1]\n",
    "\n",
    "num_inits = 5\n",
    "\n",
    "# Create equally spaced arrays for each parameter\n",
    "# remove first and last values which are on the \"face of the cube\"\n",
    "adc_inits = np.linspace(adc_lb, adc_ub, num_inits)[1:-1]\n",
    "sig_inits = np.linspace(sig_lb, sig_ub, num_inits)[1:-1]\n",
    "axr_inits = np.linspace(axr_lb, axr_ub, num_inits)[1:-1]\n",
    "\n",
    "# Generate all permutations of combinations\n",
    "all_inits = list(product(adc_inits, sig_inits, axr_inits))\n",
    "\n",
    "# Convert the list of tuples to a NumPy array\n",
    "all_inits = np.array(all_inits)\n",
    "\n",
    "sim_adc = np.random.uniform(adc_lb,adc_ub,nvox)                 # ADC, simulated [um2/ms]\n",
    "sim_sigma = np.random.uniform(sig_lb,sig_ub,nvox)               # sigma, simulated [a.u.]\n",
    "sim_axr = np.random.uniform(axr_lb,axr_ub,nvox)                 # AXR, simulated [s-1]\n",
    "\n",
    "sim_E_vox, sim_adc_prime = sim_sig_np(bf,be,tm,sim_adc,sim_sigma,sim_axr,nvox)\n",
    "\n",
    "\n",
    "#a_test1,a_test2 = sim_sig_pytorch(bf,be,tm,sim_adc,sim_sigma,sim_axr,len(sim_axr))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_bins=20\n",
    "#make 200 and voxels 100,000 to see adc prime dropoff\n",
    "fig, axs = plt.subplots(1, 3, sharey=True,figsize=(15, 5))\n",
    "axs[0].hist(sim_adc, bins=n_bins)\n",
    "axs[1].hist(sim_sigma, bins=n_bins)\n",
    "axs[2].hist(sim_axr, bins=n_bins)\n",
    "axs[0].set_title('ADC Histogram ')\n",
    "axs[0].set_xlabel('ADC Values [um^2/ms]')\n",
    "axs[1].set_title('Sigma Histogram')\n",
    "axs[1].set_xlabel('Sigma Values [arbitrary units]')\n",
    "axs[2].set_title('AXR Histogram')\n",
    "axs[2].set_xlabel('AXR Values [ms-1]');\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3,figsize=(15, 5))\n",
    "axs[0].hist(sim_E_vox.flatten(), bins=n_bins)\n",
    "axs[0].set_title('Signal Histogram ')\n",
    "axs[0].set_xlabel('Signal Values [units?]')\n",
    "axs[1].hist(sim_E_vox[sim_E_vox != 1].flatten(), bins=n_bins)\n",
    "axs[1].set_title('Signal Histogram with ones removed')\n",
    "axs[1].set_xlabel('Signal Values [units?]')\n",
    "axs[2].hist(sim_adc_prime.flatten(), bins=n_bins)\n",
    "axs[2].set_title('ADC prime Histogram')\n",
    "axs[2].set_xlabel('ADC prime Values [units?]');\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting b-value against normalised signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([be[0], be[1]], [sim_E_vox[0,0], sim_E_vox[0,1]], 'bo-')\n",
    "plt.annotate(tm[0], (be[1], sim_E_vox[0, 1]), textcoords=\"offset points\", xytext=(20,5), ha='center')\n",
    "\n",
    "plt.plot([be[2], be[3]], [sim_E_vox[0,2], sim_E_vox[0,3]], 'go-')\n",
    "plt.annotate(tm[2], (be[3], sim_E_vox[0, 3]), textcoords=\"offset points\", xytext=(20,5), ha='center')\n",
    "\n",
    "plt.plot([be[4], be[5]], [sim_E_vox[0,4], sim_E_vox[0,5]], 'ko-')\n",
    "plt.annotate(tm[4], (be[5], sim_E_vox[0, 5]), textcoords=\"offset points\", xytext=(20,5), ha='center')\n",
    "\n",
    "plt.plot([be[6], be[7]], [sim_E_vox[0,6], sim_E_vox[0,7]], 'mo-')\n",
    "plt.annotate(tm[6], (be[7], sim_E_vox[0, 7]), textcoords=\"offset points\", xytext=(20,5), ha='center')\n",
    "\n",
    "\n",
    "#plt.title('Scatter plot with 4 lines')\n",
    "plt.xlabel('Encoding block b-value [m2/s]')\n",
    "#are units correct\n",
    "plt.ylabel('Normalised Signal (sum of the magnetisations)')\n",
    "#unit?\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_adc_prime_1_vox(variables_to_optimize, tm, bf, be, smeas):\n",
    "    # For the signal from 1 voxel.\n",
    "    adc_est, sigma_est, axr_est = variables_to_optimize\n",
    "    _ , adc_tm_fit = sim_sig_np_1_vox(bf,be,tm,adc_est,sigma_est,axr_est)\n",
    "\n",
    "    bf_tm = np.column_stack((bf.flatten(), tm.flatten()))\n",
    "\n",
    "    # Find unique rows and corresponding indices\n",
    "    univols, univols_indices = np.unique(bf_tm, axis=0, return_index=True)\n",
    "\n",
    "    nsf = univols.shape[0]\n",
    "\n",
    "    ix1 = np.where((np.sum(univols[:, None, :] == bf_tm, axis=2) == 2) & (be == 0))[1]\n",
    "    ix2 = np.where((np.sum(univols[:, None, :] == bf_tm, axis=2) == 2) & (be > 0))[1]\n",
    "    \n",
    "    #this line is hardcoded\n",
    "    smeas = smeas.reshape(8)\n",
    "\n",
    "    adc_tm_calc = -1 / (be[ix2] - be[ix1]) * np.log(smeas[ix2] / smeas[ix1])\n",
    "\n",
    "    #this line is hardcoded\n",
    "    adc_tm_fit = adc_tm_fit[:, ::2]\n",
    "\n",
    "    sse = np.sum((adc_tm_calc - adc_tm_fit) ** 2)\n",
    "    return sse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z8/jwxsd17n57lblqk5c_v8fttc0000gn/T/ipykernel_90037/3568197935.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_inits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombination\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mresult_1_vox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msse_adc_prime_1_vox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_args_1_vox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult_1_vox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_sse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/z8/jwxsd17n57lblqk5c_v8fttc0000gn/T/ipykernel_90037/3672874082.py\u001b[0m in \u001b[0;36msse_adc_prime_1_vox\u001b[0;34m(variables_to_optimize, tm, bf, be, smeas)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Find unique rows and corresponding indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0munivols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munivols_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbf_tm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnsf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munivols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    314\u001b[0m     output = _unique1d(consolidated, return_index,\n\u001b[1;32m    315\u001b[0m                        return_inverse, return_counts)\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreshape_uniq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36mreshape_uniq\u001b[0;34m(uniq)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0muniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0muniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0morig_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0muniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/project/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_moveaxis_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def callback(xk):\n",
    "    print('Estimates of ADC, sigma, AXR:    ', xk)\n",
    "\n",
    "# Define the bounds for adc, sigma, axr\n",
    "bounds = tuple(map(tuple, limits.tolist())) #this line seems messy\n",
    "\n",
    "NLLS_adc_all = np.empty(shape=(0,))\n",
    "NLLS_sigma_all = np.empty(shape=(0,))\n",
    "NLLS_axr_all = np.empty(shape=(0,))\n",
    "    \n",
    "NLLS_adc_prime_all = np.empty(shape=(nvox,8))\n",
    "NLLS_E_vox_all = np.empty(shape= (nvox,8))\n",
    "\n",
    "sses = np.array([])\n",
    "for current_vox in range(nvox):\n",
    "    #reset best for each voxel\n",
    "    best_sse = 1\n",
    "\n",
    "    #extract relevant info for current voxel\n",
    "    cur_E_vox = sim_E_vox[current_vox,:]\n",
    "    cur_adc_prime = sim_adc_prime[current_vox,:]\n",
    "\n",
    "    cur_adc = sim_adc[current_vox]\n",
    "    cur_sigma = sim_sigma[current_vox]\n",
    "    cur_axr = sim_axr[current_vox]\n",
    "\n",
    "    additional_args_1_vox = (tm, bf, be, cur_E_vox) \n",
    "\n",
    "    for combination in range(all_inits.shape[0]):\n",
    "        inits = all_inits[combination,:]\n",
    "        \n",
    "        result_1_vox = scipy.optimize.minimize(sse_adc_prime_1_vox, inits, args=additional_args_1_vox, bounds=bounds)\n",
    "\n",
    "        if result_1_vox.fun < best_sse:\n",
    "            best_sse = result_1_vox.fun\n",
    "            NLLS_cur_adc, NLLS_cur_sigma, NLLS_cur_axr = result_1_vox.x\n",
    "    \n",
    "    sses = np.append(sses,best_sse)\n",
    "    # note the 1 instead of nvox, because it is for 1 voxel \n",
    "    NLLS_cur_E_vox, NLLS_cur_adc_prime = sim_sig_np_1_vox(bf,be,tm,NLLS_cur_adc, NLLS_cur_sigma, NLLS_cur_axr)\n",
    "\n",
    "    NLLS_adc_all = np.append(NLLS_adc_all, NLLS_cur_adc)\n",
    "    NLLS_sigma_all = np.append(NLLS_sigma_all, NLLS_cur_sigma)\n",
    "    NLLS_axr_all = np.append(NLLS_axr_all, NLLS_cur_axr)\n",
    "    \n",
    "    NLLS_adc_prime_all[current_vox,:] = NLLS_cur_adc_prime\n",
    "    NLLS_E_vox_all[current_vox,:] = NLLS_cur_E_vox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLLS Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging sse and seeing how large it is for the worst values. \n",
    "sses.sort()\n",
    "sses_descending = sses[::-1]\n",
    "\n",
    "\n",
    "\"\"\"MAYBE ADD LOSS PER 'EPOCH' FOR NLLS\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(loss_progress) + 1), loss_progress, marker='o', linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.grid(True)\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\n",
    "#plotting the sse\n",
    "plt.figure()\n",
    "plt.hist(sses.flatten(), bins=200)\n",
    "\n",
    "plt.figure()\n",
    "# for first voxel\n",
    "plt.scatter(be, sim_E_vox[0,:], label='simulated')\n",
    "plt.scatter(be, NLLS_E_vox_all[0,:], label='predicted')\n",
    "plt.xlabel(\"be\")\n",
    "plt.ylabel(\"tm\")\n",
    "plt.legend()\n",
    "\n",
    "# plot scatter plots to analyse correlation of predicted free params against ground truth\n",
    "plt.figure()\n",
    "\n",
    "param_sim = [sim_adc, sim_sigma, sim_axr]\n",
    "param_pred = [NLLS_adc_all, NLLS_sigma_all, NLLS_axr_all]\n",
    "param_name = ['ADC', 'Sigma', 'AXR']\n",
    "\n",
    "rvals = []\n",
    "\n",
    "for i,_ in enumerate(param_sim):\n",
    "    plt.rcParams['font.size'] = '16'\n",
    "    plt.scatter(param_sim[i], param_pred[i], s=2, c='navy')\n",
    "    plt.xlabel(param_name[i] + ' Ground Truth')\n",
    "    plt.ylabel(param_name[i] + ' Prediction')\n",
    "    #check what line below does. Commented out because it gave an error when using 1 voxel\n",
    "    #rvals.append(scipy.stats.pearsonr(np.squeeze(param_sim[i]), np.squeeze(param_pred[i])))\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "\n",
    "print(rvals)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): # this is the neural network\n",
    "    #defining the init and foward pass functions. \n",
    "\n",
    "    def __init__(self,be,bf,tm,nparams,limits):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.be = be\n",
    "        self.bf = bf\n",
    "        self.tm = tm\n",
    "        self.limits = limits\n",
    "\n",
    "        #defining the layers that we want. \n",
    "        # 3 layers with no. of be nodes. \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(3): # 3 fully connected hidden layers\n",
    "            self.layers.extend([nn.Linear(len(be), len(be)), nn.PReLU()])\n",
    "            #https://pytorch.org/docs/stable/generated/torch.nn.PReLU.html\n",
    "        self.encoder = nn.Sequential(*self.layers, nn.Linear(len(be), nparams))\n",
    "\n",
    "    def forward(self, E_vox):\n",
    "\n",
    "        params = torch.nn.functional.softplus(self.encoder(E_vox))\n",
    "        #running a forward pass through the network\n",
    "\n",
    "        #SoftPlus is a smooth approximation to the ReLU function and can be used to constrain the output of a machine to always be positive\n",
    "        #params contains batch_size x nparams outputs, so each row is adc, sigma and axr.\n",
    "\n",
    "        #unsqueeze adds an additional dimension. \n",
    "        #parameter constraints from Elizabeth matlab \n",
    "\n",
    "        adc = torch.clamp(params[:, 0].unsqueeze(1), min=limits[0,0], max=limits[0,1])\n",
    "        sigma = torch.clamp(params[:, 1].unsqueeze(1), min=limits[1,0], max=limits[1,1])\n",
    "        axr = torch.clamp(params[:, 2].unsqueeze(1), min=limits[2,0], max=limits[2,1])\n",
    "        \n",
    "        self.tm[(self.tm == torch.min(self.tm)) & (self.bf == 0)] = float('inf')\n",
    "\n",
    "        adc_prime = adc * (1 - sigma * torch.exp(-tm * axr))\n",
    "        E_vox = torch.exp(-adc_prime * be)\n",
    "\n",
    "        \"\"\"print(\"tm:\", self.tm.shape)\n",
    "        print(\"be:\", self.be.shape)\n",
    "        print(\"bf:\", self.bf.shape)\n",
    "        print(\"adc:\", adc.shape)\n",
    "        print(\"sigma:\", sigma.shape)\n",
    "        print(\"axr:\", axr.shape)\n",
    "        print(\"evox:\", E_vox.shape)\"\"\"\n",
    "\n",
    "        print(\"self.encoder(E_vox)\", self.encoder(E_vox)[0,:])\n",
    "        print(\"params:\", params[0,:])\n",
    "        print(\"adc:\", adc)\n",
    "        print(\"sigma:\", sigma)\n",
    "        print(\"axr:\", axr)\n",
    "        print(\"evox:\", E_vox)\n",
    "\n",
    "        return E_vox, adc_prime, adc, sigma, axr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "nparams = 3\n",
    "#because of adc, sigma and axr\n",
    "\n",
    "#converting numpy arrays to pytorch tensors. \n",
    "#be = torch.tensor(be)\n",
    "#bf = torch.tensor(bf)\n",
    "#tm = torch.tensor(tm)\n",
    "be = torch.tensor(be, dtype=torch.float32)\n",
    "bf = torch.tensor(bf, dtype=torch.float32)\n",
    "tm = torch.tensor(tm, dtype=torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "#initilise network\n",
    "net = Net(be, bf, tm, nparams,limits)\n",
    "\n",
    "#create batch queues for data\n",
    "#// means divide and round down. \n",
    "num_batches = len(sim_E_vox) // batch_size\n",
    "\n",
    "#import the sim_E_vox array into the dataloader\n",
    "#drop_last ignores the last batch if it is the wrong size. \n",
    "#num_workers is about performance. \n",
    "\n",
    "trainloader = utils.DataLoader(torch.from_numpy(sim_E_vox.astype(np.float32)),\n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = True,\n",
    "                                num_workers = 0, #was 2 previously\n",
    "                                drop_last = True)\n",
    "\n",
    "# loss function and optimizer\n",
    "#choosing which loss function to use. \n",
    "#not sure what the optmizer is\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "# best loss\n",
    "best = 1e16\n",
    "num_bad_epochs = 0\n",
    "#can increase patience a lot, speed not an issue.\n",
    "patience = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "epoch: 0; bad epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 57.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([ 0.1864, -0.1575,  0.1987], grad_fn=<SliceBackward0>)\n",
      "params: tensor([0.7910, 0.6174, 0.7988], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[0.7910],\n",
      "        [0.7909],\n",
      "        [0.7904],\n",
      "        [0.7899],\n",
      "        [0.7889],\n",
      "        [0.7911],\n",
      "        [0.7904],\n",
      "        [0.7907],\n",
      "        [0.7904],\n",
      "        [0.7911],\n",
      "        [0.7912],\n",
      "        [0.7909],\n",
      "        [0.7904],\n",
      "        [0.7910],\n",
      "        [0.7894],\n",
      "        [0.7903],\n",
      "        [0.7899],\n",
      "        [0.7911],\n",
      "        [0.7904],\n",
      "        [0.7907],\n",
      "        [0.7909],\n",
      "        [0.7906],\n",
      "        [0.7897],\n",
      "        [0.7902],\n",
      "        [0.7890],\n",
      "        [0.7911],\n",
      "        [0.7896],\n",
      "        [0.7909],\n",
      "        [0.7900],\n",
      "        [0.7897],\n",
      "        [0.7897],\n",
      "        [0.7900],\n",
      "        [0.7908],\n",
      "        [0.7910],\n",
      "        [0.7911],\n",
      "        [0.7905],\n",
      "        [0.7908],\n",
      "        [0.7906],\n",
      "        [0.7898],\n",
      "        [0.7903],\n",
      "        [0.7910],\n",
      "        [0.7912],\n",
      "        [0.7899],\n",
      "        [0.7901],\n",
      "        [0.7903],\n",
      "        [0.7912],\n",
      "        [0.7905],\n",
      "        [0.7897],\n",
      "        [0.7908],\n",
      "        [0.7899],\n",
      "        [0.7911],\n",
      "        [0.7901],\n",
      "        [0.7907],\n",
      "        [0.7909],\n",
      "        [0.7901],\n",
      "        [0.7891],\n",
      "        [0.7903],\n",
      "        [0.7901],\n",
      "        [0.7893],\n",
      "        [0.7896],\n",
      "        [0.7905],\n",
      "        [0.7901],\n",
      "        [0.7910],\n",
      "        [0.7912],\n",
      "        [0.7896],\n",
      "        [0.7898],\n",
      "        [0.7910],\n",
      "        [0.7898],\n",
      "        [0.7904],\n",
      "        [0.7909],\n",
      "        [0.7902],\n",
      "        [0.7905],\n",
      "        [0.7894],\n",
      "        [0.7910],\n",
      "        [0.7888],\n",
      "        [0.7896],\n",
      "        [0.7901],\n",
      "        [0.7909],\n",
      "        [0.7904],\n",
      "        [0.7906],\n",
      "        [0.7899],\n",
      "        [0.7900],\n",
      "        [0.7911],\n",
      "        [0.7910],\n",
      "        [0.7906],\n",
      "        [0.7910],\n",
      "        [0.7911],\n",
      "        [0.7896],\n",
      "        [0.7910],\n",
      "        [0.7893],\n",
      "        [0.7902],\n",
      "        [0.7911],\n",
      "        [0.7911],\n",
      "        [0.7902],\n",
      "        [0.7905],\n",
      "        [0.7902],\n",
      "        [0.7907],\n",
      "        [0.7910],\n",
      "        [0.7891],\n",
      "        [0.7911],\n",
      "        [0.7902],\n",
      "        [0.7910],\n",
      "        [0.7892],\n",
      "        [0.7908],\n",
      "        [0.7898],\n",
      "        [0.7902],\n",
      "        [0.7890],\n",
      "        [0.7911],\n",
      "        [0.7892],\n",
      "        [0.7908],\n",
      "        [0.7895],\n",
      "        [0.7897],\n",
      "        [0.7899],\n",
      "        [0.7900],\n",
      "        [0.7898],\n",
      "        [0.7903],\n",
      "        [0.7911],\n",
      "        [0.7906],\n",
      "        [0.7895],\n",
      "        [0.7911],\n",
      "        [0.7911],\n",
      "        [0.7908],\n",
      "        [0.7911],\n",
      "        [0.7895],\n",
      "        [0.7907],\n",
      "        [0.7902],\n",
      "        [0.7911],\n",
      "        [0.7911]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[0.6174],\n",
      "        [0.6179],\n",
      "        [0.6177],\n",
      "        [0.6179],\n",
      "        [0.6180],\n",
      "        [0.6173],\n",
      "        [0.6177],\n",
      "        [0.6176],\n",
      "        [0.6177],\n",
      "        [0.6175],\n",
      "        [0.6175],\n",
      "        [0.6174],\n",
      "        [0.6185],\n",
      "        [0.6175],\n",
      "        [0.6178],\n",
      "        [0.6180],\n",
      "        [0.6177],\n",
      "        [0.6173],\n",
      "        [0.6179],\n",
      "        [0.6180],\n",
      "        [0.6180],\n",
      "        [0.6179],\n",
      "        [0.6179],\n",
      "        [0.6177],\n",
      "        [0.6179],\n",
      "        [0.6174],\n",
      "        [0.6180],\n",
      "        [0.6176],\n",
      "        [0.6177],\n",
      "        [0.6180],\n",
      "        [0.6177],\n",
      "        [0.6180],\n",
      "        [0.6176],\n",
      "        [0.6178],\n",
      "        [0.6175],\n",
      "        [0.6181],\n",
      "        [0.6179],\n",
      "        [0.6176],\n",
      "        [0.6180],\n",
      "        [0.6179],\n",
      "        [0.6174],\n",
      "        [0.6177],\n",
      "        [0.6179],\n",
      "        [0.6177],\n",
      "        [0.6176],\n",
      "        [0.6175],\n",
      "        [0.6178],\n",
      "        [0.6184],\n",
      "        [0.6178],\n",
      "        [0.6179],\n",
      "        [0.6179],\n",
      "        [0.6178],\n",
      "        [0.6176],\n",
      "        [0.6178],\n",
      "        [0.6178],\n",
      "        [0.6179],\n",
      "        [0.6181],\n",
      "        [0.6181],\n",
      "        [0.6178],\n",
      "        [0.6179],\n",
      "        [0.6179],\n",
      "        [0.6183],\n",
      "        [0.6175],\n",
      "        [0.6178],\n",
      "        [0.6178],\n",
      "        [0.6178],\n",
      "        [0.6177],\n",
      "        [0.6179],\n",
      "        [0.6180],\n",
      "        [0.6175],\n",
      "        [0.6182],\n",
      "        [0.6181],\n",
      "        [0.6179],\n",
      "        [0.6174],\n",
      "        [0.6179],\n",
      "        [0.6178],\n",
      "        [0.6181],\n",
      "        [0.6180],\n",
      "        [0.6178],\n",
      "        [0.6179],\n",
      "        [0.6183],\n",
      "        [0.6178],\n",
      "        [0.6176],\n",
      "        [0.6178],\n",
      "        [0.6181],\n",
      "        [0.6178],\n",
      "        [0.6177],\n",
      "        [0.6178],\n",
      "        [0.6174],\n",
      "        [0.6179],\n",
      "        [0.6178],\n",
      "        [0.6176],\n",
      "        [0.6177],\n",
      "        [0.6183],\n",
      "        [0.6182],\n",
      "        [0.6181],\n",
      "        [0.6177],\n",
      "        [0.6178],\n",
      "        [0.6177],\n",
      "        [0.6176],\n",
      "        [0.6179],\n",
      "        [0.6174],\n",
      "        [0.6181],\n",
      "        [0.6177],\n",
      "        [0.6180],\n",
      "        [0.6182],\n",
      "        [0.6179],\n",
      "        [0.6176],\n",
      "        [0.6179],\n",
      "        [0.6183],\n",
      "        [0.6181],\n",
      "        [0.6182],\n",
      "        [0.6182],\n",
      "        [0.6178],\n",
      "        [0.6180],\n",
      "        [0.6181],\n",
      "        [0.6174],\n",
      "        [0.6181],\n",
      "        [0.6180],\n",
      "        [0.6176],\n",
      "        [0.6174],\n",
      "        [0.6176],\n",
      "        [0.6174],\n",
      "        [0.6179],\n",
      "        [0.6180],\n",
      "        [0.6181],\n",
      "        [0.6175],\n",
      "        [0.6178]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[0.7988],\n",
      "        [0.7986],\n",
      "        [0.7980],\n",
      "        [0.7976],\n",
      "        [0.7960],\n",
      "        [0.7987],\n",
      "        [0.7978],\n",
      "        [0.7983],\n",
      "        [0.7978],\n",
      "        [0.7992],\n",
      "        [0.7992],\n",
      "        [0.7985],\n",
      "        [0.7988],\n",
      "        [0.7987],\n",
      "        [0.7966],\n",
      "        [0.7986],\n",
      "        [0.7971],\n",
      "        [0.7987],\n",
      "        [0.7987],\n",
      "        [0.7988],\n",
      "        [0.7995],\n",
      "        [0.7988],\n",
      "        [0.7971],\n",
      "        [0.7977],\n",
      "        [0.7962],\n",
      "        [0.7990],\n",
      "        [0.7968],\n",
      "        [0.7985],\n",
      "        [0.7973],\n",
      "        [0.7973],\n",
      "        [0.7961],\n",
      "        [0.7982],\n",
      "        [0.7981],\n",
      "        [0.7987],\n",
      "        [0.7992],\n",
      "        [0.7993],\n",
      "        [0.7988],\n",
      "        [0.7980],\n",
      "        [0.7978],\n",
      "        [0.7985],\n",
      "        [0.7988],\n",
      "        [0.7994],\n",
      "        [0.7958],\n",
      "        [0.7976],\n",
      "        [0.7964],\n",
      "        [0.7993],\n",
      "        [0.7981],\n",
      "        [0.7971],\n",
      "        [0.7990],\n",
      "        [0.7976],\n",
      "        [0.7995],\n",
      "        [0.7978],\n",
      "        [0.7978],\n",
      "        [0.7991],\n",
      "        [0.7971],\n",
      "        [0.7964],\n",
      "        [0.7990],\n",
      "        [0.7980],\n",
      "        [0.7964],\n",
      "        [0.7970],\n",
      "        [0.7986],\n",
      "        [0.7969],\n",
      "        [0.7988],\n",
      "        [0.7995],\n",
      "        [0.7969],\n",
      "        [0.7972],\n",
      "        [0.7988],\n",
      "        [0.7972],\n",
      "        [0.7990],\n",
      "        [0.7985],\n",
      "        [0.7989],\n",
      "        [0.7991],\n",
      "        [0.7965],\n",
      "        [0.7988],\n",
      "        [0.7956],\n",
      "        [0.7967],\n",
      "        [0.7987],\n",
      "        [0.7996],\n",
      "        [0.7982],\n",
      "        [0.7990],\n",
      "        [0.7981],\n",
      "        [0.7961],\n",
      "        [0.7990],\n",
      "        [0.7992],\n",
      "        [0.7996],\n",
      "        [0.7992],\n",
      "        [0.7993],\n",
      "        [0.7956],\n",
      "        [0.7987],\n",
      "        [0.7965],\n",
      "        [0.7977],\n",
      "        [0.7992],\n",
      "        [0.7992],\n",
      "        [0.7982],\n",
      "        [0.7995],\n",
      "        [0.7983],\n",
      "        [0.7982],\n",
      "        [0.7992],\n",
      "        [0.7936],\n",
      "        [0.7991],\n",
      "        [0.7977],\n",
      "        [0.7988],\n",
      "        [0.7967],\n",
      "        [0.7986],\n",
      "        [0.7976],\n",
      "        [0.7988],\n",
      "        [0.7962],\n",
      "        [0.7992],\n",
      "        [0.7967],\n",
      "        [0.7999],\n",
      "        [0.7972],\n",
      "        [0.7977],\n",
      "        [0.7981],\n",
      "        [0.7976],\n",
      "        [0.7980],\n",
      "        [0.7985],\n",
      "        [0.7990],\n",
      "        [0.7995],\n",
      "        [0.7973],\n",
      "        [0.7993],\n",
      "        [0.7991],\n",
      "        [0.7984],\n",
      "        [0.7991],\n",
      "        [0.7967],\n",
      "        [0.7993],\n",
      "        [0.7987],\n",
      "        [0.7991],\n",
      "        [0.7996]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[1.0000, 0.8206, 1.0000,  ..., 0.9106, 1.0000, 0.8967],\n",
      "        [1.0000, 0.8206, 1.0000,  ..., 0.9107, 1.0000, 0.8968],\n",
      "        [1.0000, 0.8207, 1.0000,  ..., 0.9107, 1.0000, 0.8968],\n",
      "        ...,\n",
      "        [1.0000, 0.8207, 1.0000,  ..., 0.9108, 1.0000, 0.8969],\n",
      "        [1.0000, 0.8206, 1.0000,  ..., 0.9106, 1.0000, 0.8967],\n",
      "        [1.0000, 0.8205, 1.0000,  ..., 0.9106, 1.0000, 0.8967]],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 1; bad epochs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 39.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 2; bad epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 37.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 3; bad epochs: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 58.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 4; bad epochs: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 71.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 5; bad epochs: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 40.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 6; bad epochs: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 53.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 7; bad epochs: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 71.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 8; bad epochs: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 55.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "-----------------------------------------------------------------\n",
      "epoch: 9; bad epochs: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 5/7 [00:00<00:00, 49.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder(E_vox) tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "params: tensor([nan, nan, nan], grad_fn=<SliceBackward0>)\n",
      "adc: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "sigma: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "axr: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ClampBackward1>)\n",
      "evox: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<ExpBackward0>)\n",
      "evox nan found\n",
      "pred_adc nan found\n",
      "pred_axr nan found\n",
      "sigpred_sigma nan found\n",
      "loss: nan\n",
      "done, best loss: 1e+16\n",
      "done\n",
      "self.encoder(E_vox) tensor([ 1.5261, -0.9979, -0.7375])\n",
      "params: tensor([1.7081, 0.3195, 0.3963])\n",
      "adc: tensor([[1.7081],\n",
      "        [1.6963],\n",
      "        [1.6713],\n",
      "        [1.7295],\n",
      "        [1.7311],\n",
      "        [1.7180],\n",
      "        [1.7452],\n",
      "        [1.7044],\n",
      "        [1.7311],\n",
      "        [1.7465],\n",
      "        [1.6807],\n",
      "        [1.7047],\n",
      "        [1.7303],\n",
      "        [1.7207],\n",
      "        [1.7300],\n",
      "        [1.6928],\n",
      "        [1.6966],\n",
      "        [1.6845],\n",
      "        [1.7651],\n",
      "        [1.6750],\n",
      "        [1.7133],\n",
      "        [1.6864],\n",
      "        [1.7272],\n",
      "        [1.7402],\n",
      "        [1.6932],\n",
      "        [1.7733],\n",
      "        [1.7264],\n",
      "        [1.7509],\n",
      "        [1.7754],\n",
      "        [1.7065],\n",
      "        [1.7721],\n",
      "        [1.7041],\n",
      "        [1.7307],\n",
      "        [1.7597],\n",
      "        [1.6887],\n",
      "        [1.7605],\n",
      "        [1.7092],\n",
      "        [1.6794],\n",
      "        [1.7098],\n",
      "        [1.7442],\n",
      "        [1.7658],\n",
      "        [1.6863],\n",
      "        [1.6950],\n",
      "        [1.6847],\n",
      "        [1.7473],\n",
      "        [1.7288],\n",
      "        [1.7418],\n",
      "        [1.7033],\n",
      "        [1.6838],\n",
      "        [1.6917],\n",
      "        [1.7324],\n",
      "        [1.6658],\n",
      "        [1.7057],\n",
      "        [1.6962],\n",
      "        [1.7090],\n",
      "        [1.7553],\n",
      "        [1.7755],\n",
      "        [1.6732],\n",
      "        [1.7330],\n",
      "        [1.7298],\n",
      "        [1.6715],\n",
      "        [1.7178],\n",
      "        [1.7025],\n",
      "        [1.7049],\n",
      "        [1.6912],\n",
      "        [1.7202],\n",
      "        [1.7309],\n",
      "        [1.7262],\n",
      "        [1.7009],\n",
      "        [1.7452],\n",
      "        [1.7334],\n",
      "        [1.6946],\n",
      "        [1.7269],\n",
      "        [1.7599],\n",
      "        [1.7177],\n",
      "        [1.6716],\n",
      "        [1.6748],\n",
      "        [1.7001],\n",
      "        [1.6693],\n",
      "        [1.7328],\n",
      "        [1.6782],\n",
      "        [1.7633],\n",
      "        [1.7110],\n",
      "        [1.6939],\n",
      "        [1.7235],\n",
      "        [1.7067],\n",
      "        [1.7848],\n",
      "        [1.7304],\n",
      "        [1.7687],\n",
      "        [1.6888],\n",
      "        [1.6635],\n",
      "        [1.6853],\n",
      "        [1.7632],\n",
      "        [1.7078],\n",
      "        [1.6681],\n",
      "        [1.7051],\n",
      "        [1.7470],\n",
      "        [1.7861],\n",
      "        [1.6889],\n",
      "        [1.7359],\n",
      "        [1.7391],\n",
      "        [1.7379],\n",
      "        [1.6912],\n",
      "        [1.6825],\n",
      "        [1.6914],\n",
      "        [1.7704],\n",
      "        [1.7139],\n",
      "        [1.6792],\n",
      "        [1.6975],\n",
      "        [1.7522],\n",
      "        [1.7310],\n",
      "        [1.6970],\n",
      "        [1.7328],\n",
      "        [1.7699],\n",
      "        [1.7492],\n",
      "        [1.6916],\n",
      "        [1.6990],\n",
      "        [1.6848],\n",
      "        [1.7112],\n",
      "        [1.7331],\n",
      "        [1.7085],\n",
      "        [1.6767],\n",
      "        [1.7059],\n",
      "        [1.7797],\n",
      "        [1.7220],\n",
      "        [1.6914],\n",
      "        [1.7648],\n",
      "        [1.6768],\n",
      "        [1.7519],\n",
      "        [1.7495],\n",
      "        [1.6788],\n",
      "        [1.7692],\n",
      "        [1.7621],\n",
      "        [1.6860],\n",
      "        [1.6862],\n",
      "        [1.7099],\n",
      "        [1.6819],\n",
      "        [1.6766],\n",
      "        [1.6932],\n",
      "        [1.7112],\n",
      "        [1.6761],\n",
      "        [1.7699],\n",
      "        [1.6693],\n",
      "        [1.7433],\n",
      "        [1.7297],\n",
      "        [1.7716],\n",
      "        [1.6752],\n",
      "        [1.6643],\n",
      "        [1.6945],\n",
      "        [1.7117],\n",
      "        [1.7308],\n",
      "        [1.6691],\n",
      "        [1.7757],\n",
      "        [1.6674],\n",
      "        [1.7492],\n",
      "        [1.7613],\n",
      "        [1.7221],\n",
      "        [1.7159],\n",
      "        [1.6779],\n",
      "        [1.7412],\n",
      "        [1.7095],\n",
      "        [1.7101],\n",
      "        [1.7836],\n",
      "        [1.7114],\n",
      "        [1.7794],\n",
      "        [1.6692],\n",
      "        [1.7590],\n",
      "        [1.7223],\n",
      "        [1.6804],\n",
      "        [1.7170],\n",
      "        [1.7278],\n",
      "        [1.7720],\n",
      "        [1.7042],\n",
      "        [1.7646],\n",
      "        [1.7116],\n",
      "        [1.7693],\n",
      "        [1.7206],\n",
      "        [1.7704],\n",
      "        [1.7211],\n",
      "        [1.7582],\n",
      "        [1.7223],\n",
      "        [1.6821],\n",
      "        [1.7182],\n",
      "        [1.6782],\n",
      "        [1.7167],\n",
      "        [1.7401],\n",
      "        [1.6865],\n",
      "        [1.7503],\n",
      "        [1.6759],\n",
      "        [1.7220],\n",
      "        [1.6875],\n",
      "        [1.7621],\n",
      "        [1.7571],\n",
      "        [1.7324],\n",
      "        [1.7506],\n",
      "        [1.7360],\n",
      "        [1.6794],\n",
      "        [1.7237],\n",
      "        [1.6686],\n",
      "        [1.7078],\n",
      "        [1.7368],\n",
      "        [1.7086],\n",
      "        [1.6714],\n",
      "        [1.7088],\n",
      "        [1.6717],\n",
      "        [1.7019],\n",
      "        [1.6700],\n",
      "        [1.7737],\n",
      "        [1.7387],\n",
      "        [1.6866],\n",
      "        [1.7590],\n",
      "        [1.6986],\n",
      "        [1.6854],\n",
      "        [1.7528],\n",
      "        [1.7283],\n",
      "        [1.7457],\n",
      "        [1.7042],\n",
      "        [1.7791],\n",
      "        [1.7595],\n",
      "        [1.6814],\n",
      "        [1.6737],\n",
      "        [1.7238],\n",
      "        [1.7381],\n",
      "        [1.7355],\n",
      "        [1.6921],\n",
      "        [1.7784],\n",
      "        [1.7186],\n",
      "        [1.6736],\n",
      "        [1.6990],\n",
      "        [1.6657],\n",
      "        [1.7365],\n",
      "        [1.7552],\n",
      "        [1.6861],\n",
      "        [1.6700],\n",
      "        [1.6778],\n",
      "        [1.6967],\n",
      "        [1.6982],\n",
      "        [1.7435],\n",
      "        [1.6749],\n",
      "        [1.7652],\n",
      "        [1.7608],\n",
      "        [1.7039],\n",
      "        [1.7458],\n",
      "        [1.7207],\n",
      "        [1.7839],\n",
      "        [1.7413],\n",
      "        [1.7384],\n",
      "        [1.7670],\n",
      "        [1.7753],\n",
      "        [1.6934],\n",
      "        [1.7455],\n",
      "        [1.7713],\n",
      "        [1.6668],\n",
      "        [1.6893],\n",
      "        [1.7672],\n",
      "        [1.7115],\n",
      "        [1.7389],\n",
      "        [1.7747],\n",
      "        [1.7398],\n",
      "        [1.7647],\n",
      "        [1.6930],\n",
      "        [1.7522],\n",
      "        [1.6781],\n",
      "        [1.6708],\n",
      "        [1.7529],\n",
      "        [1.6857],\n",
      "        [1.7048],\n",
      "        [1.6985],\n",
      "        [1.6991],\n",
      "        [1.7388],\n",
      "        [1.7171],\n",
      "        [1.7662],\n",
      "        [1.6951],\n",
      "        [1.6924],\n",
      "        [1.6751],\n",
      "        [1.7256],\n",
      "        [1.6873],\n",
      "        [1.7205],\n",
      "        [1.7235],\n",
      "        [1.7001],\n",
      "        [1.6745],\n",
      "        [1.7619],\n",
      "        [1.6909],\n",
      "        [1.6796],\n",
      "        [1.7143],\n",
      "        [1.7002],\n",
      "        [1.7643],\n",
      "        [1.7260],\n",
      "        [1.7834],\n",
      "        [1.6858],\n",
      "        [1.6704],\n",
      "        [1.6813],\n",
      "        [1.7487],\n",
      "        [1.7182],\n",
      "        [1.6737],\n",
      "        [1.6874],\n",
      "        [1.6784],\n",
      "        [1.7400],\n",
      "        [1.6910],\n",
      "        [1.7841],\n",
      "        [1.6711],\n",
      "        [1.7623],\n",
      "        [1.7041],\n",
      "        [1.6806],\n",
      "        [1.7201],\n",
      "        [1.6920],\n",
      "        [1.7567],\n",
      "        [1.6922],\n",
      "        [1.6750],\n",
      "        [1.6752],\n",
      "        [1.6923],\n",
      "        [1.7586],\n",
      "        [1.7036],\n",
      "        [1.7683],\n",
      "        [1.7152],\n",
      "        [1.7738],\n",
      "        [1.6888],\n",
      "        [1.7124],\n",
      "        [1.7320],\n",
      "        [1.6920],\n",
      "        [1.7531],\n",
      "        [1.6887],\n",
      "        [1.7056],\n",
      "        [1.7392],\n",
      "        [1.7060],\n",
      "        [1.7640],\n",
      "        [1.7432],\n",
      "        [1.6914],\n",
      "        [1.6947],\n",
      "        [1.6897],\n",
      "        [1.7608],\n",
      "        [1.7260],\n",
      "        [1.7462],\n",
      "        [1.6668],\n",
      "        [1.6885],\n",
      "        [1.7322],\n",
      "        [1.7247],\n",
      "        [1.7196],\n",
      "        [1.7275],\n",
      "        [1.7046],\n",
      "        [1.7427],\n",
      "        [1.7090],\n",
      "        [1.7573],\n",
      "        [1.7379],\n",
      "        [1.6842],\n",
      "        [1.6982],\n",
      "        [1.7656],\n",
      "        [1.7125],\n",
      "        [1.7138],\n",
      "        [1.7357],\n",
      "        [1.6784],\n",
      "        [1.7642],\n",
      "        [1.7100],\n",
      "        [1.6912],\n",
      "        [1.7627],\n",
      "        [1.6924],\n",
      "        [1.6664],\n",
      "        [1.6780],\n",
      "        [1.7106],\n",
      "        [1.7789],\n",
      "        [1.7645],\n",
      "        [1.7376],\n",
      "        [1.7050],\n",
      "        [1.6820],\n",
      "        [1.7112],\n",
      "        [1.6831],\n",
      "        [1.7441],\n",
      "        [1.7463],\n",
      "        [1.6785],\n",
      "        [1.7009],\n",
      "        [1.6925],\n",
      "        [1.7420],\n",
      "        [1.7012],\n",
      "        [1.7839],\n",
      "        [1.7445],\n",
      "        [1.7040],\n",
      "        [1.7069],\n",
      "        [1.6796],\n",
      "        [1.6868],\n",
      "        [1.7001],\n",
      "        [1.6712],\n",
      "        [1.6730],\n",
      "        [1.7644],\n",
      "        [1.7492],\n",
      "        [1.6853],\n",
      "        [1.7253],\n",
      "        [1.7046],\n",
      "        [1.7277],\n",
      "        [1.6679],\n",
      "        [1.7402],\n",
      "        [1.7047],\n",
      "        [1.7295],\n",
      "        [1.7342],\n",
      "        [1.7536],\n",
      "        [1.6808],\n",
      "        [1.7733],\n",
      "        [1.6910],\n",
      "        [1.7281],\n",
      "        [1.7535],\n",
      "        [1.6992],\n",
      "        [1.7270],\n",
      "        [1.6999],\n",
      "        [1.7036],\n",
      "        [1.7454],\n",
      "        [1.7510],\n",
      "        [1.7213],\n",
      "        [1.7246],\n",
      "        [1.7636],\n",
      "        [1.6906],\n",
      "        [1.6777],\n",
      "        [1.6859],\n",
      "        [1.7682],\n",
      "        [1.7002],\n",
      "        [1.6924],\n",
      "        [1.6686],\n",
      "        [1.7684],\n",
      "        [1.7555],\n",
      "        [1.7268],\n",
      "        [1.6996],\n",
      "        [1.6947],\n",
      "        [1.7525],\n",
      "        [1.7101],\n",
      "        [1.6735],\n",
      "        [1.7079],\n",
      "        [1.6816],\n",
      "        [1.7088],\n",
      "        [1.7446],\n",
      "        [1.7019],\n",
      "        [1.7218],\n",
      "        [1.6974],\n",
      "        [1.7387],\n",
      "        [1.6961],\n",
      "        [1.7491],\n",
      "        [1.6733],\n",
      "        [1.6713],\n",
      "        [1.6662],\n",
      "        [1.6959],\n",
      "        [1.6729],\n",
      "        [1.6946],\n",
      "        [1.6719],\n",
      "        [1.7168],\n",
      "        [1.7543],\n",
      "        [1.6914],\n",
      "        [1.7161],\n",
      "        [1.7141],\n",
      "        [1.7472],\n",
      "        [1.6698],\n",
      "        [1.6986],\n",
      "        [1.7235],\n",
      "        [1.7661],\n",
      "        [1.7561],\n",
      "        [1.7209],\n",
      "        [1.6841],\n",
      "        [1.7346],\n",
      "        [1.6992],\n",
      "        [1.6933],\n",
      "        [1.6796],\n",
      "        [1.7028],\n",
      "        [1.6660],\n",
      "        [1.7026],\n",
      "        [1.7065],\n",
      "        [1.7304],\n",
      "        [1.7578],\n",
      "        [1.7734],\n",
      "        [1.7478],\n",
      "        [1.7574],\n",
      "        [1.7411],\n",
      "        [1.7476],\n",
      "        [1.7303],\n",
      "        [1.7486],\n",
      "        [1.7019],\n",
      "        [1.7194],\n",
      "        [1.6950],\n",
      "        [1.7202],\n",
      "        [1.6942],\n",
      "        [1.7317],\n",
      "        [1.7317],\n",
      "        [1.7175],\n",
      "        [1.6917],\n",
      "        [1.6714],\n",
      "        [1.7820],\n",
      "        [1.7544],\n",
      "        [1.6827],\n",
      "        [1.6968],\n",
      "        [1.7813],\n",
      "        [1.7325],\n",
      "        [1.7623],\n",
      "        [1.6992],\n",
      "        [1.7179],\n",
      "        [1.7082],\n",
      "        [1.7141],\n",
      "        [1.7372],\n",
      "        [1.7048],\n",
      "        [1.6978],\n",
      "        [1.6867],\n",
      "        [1.7002],\n",
      "        [1.7737],\n",
      "        [1.6711],\n",
      "        [1.7405],\n",
      "        [1.7493],\n",
      "        [1.7038],\n",
      "        [1.7052],\n",
      "        [1.6663],\n",
      "        [1.7809],\n",
      "        [1.6881],\n",
      "        [1.7723],\n",
      "        [1.7445],\n",
      "        [1.7823],\n",
      "        [1.7634],\n",
      "        [1.7485],\n",
      "        [1.7179],\n",
      "        [1.7666],\n",
      "        [1.6706],\n",
      "        [1.7464],\n",
      "        [1.7501],\n",
      "        [1.6921],\n",
      "        [1.7239],\n",
      "        [1.7060],\n",
      "        [1.7509],\n",
      "        [1.7368],\n",
      "        [1.7585],\n",
      "        [1.6968],\n",
      "        [1.7779],\n",
      "        [1.7433],\n",
      "        [1.7008],\n",
      "        [1.7668],\n",
      "        [1.7505],\n",
      "        [1.6757],\n",
      "        [1.6990],\n",
      "        [1.7539],\n",
      "        [1.6789],\n",
      "        [1.7096],\n",
      "        [1.7718],\n",
      "        [1.7700],\n",
      "        [1.7333],\n",
      "        [1.7168],\n",
      "        [1.7037],\n",
      "        [1.6829],\n",
      "        [1.7555],\n",
      "        [1.7108],\n",
      "        [1.7737],\n",
      "        [1.7562],\n",
      "        [1.7186],\n",
      "        [1.7097],\n",
      "        [1.6920],\n",
      "        [1.7591],\n",
      "        [1.7144],\n",
      "        [1.6870],\n",
      "        [1.7709],\n",
      "        [1.6775],\n",
      "        [1.7493],\n",
      "        [1.7535],\n",
      "        [1.6885],\n",
      "        [1.7639],\n",
      "        [1.7479],\n",
      "        [1.7834],\n",
      "        [1.7630],\n",
      "        [1.7728],\n",
      "        [1.7018],\n",
      "        [1.7503],\n",
      "        [1.7040],\n",
      "        [1.6938],\n",
      "        [1.7057],\n",
      "        [1.6656],\n",
      "        [1.7571],\n",
      "        [1.7129],\n",
      "        [1.7017],\n",
      "        [1.7247],\n",
      "        [1.7173],\n",
      "        [1.7014],\n",
      "        [1.7061],\n",
      "        [1.6642],\n",
      "        [1.6778],\n",
      "        [1.7035],\n",
      "        [1.7525],\n",
      "        [1.7791],\n",
      "        [1.7135],\n",
      "        [1.7119],\n",
      "        [1.7597],\n",
      "        [1.6678],\n",
      "        [1.6680],\n",
      "        [1.7103],\n",
      "        [1.7178],\n",
      "        [1.6707],\n",
      "        [1.7004],\n",
      "        [1.7667],\n",
      "        [1.7192],\n",
      "        [1.7290],\n",
      "        [1.7390],\n",
      "        [1.7548],\n",
      "        [1.7177],\n",
      "        [1.7491],\n",
      "        [1.6681],\n",
      "        [1.7070],\n",
      "        [1.7793],\n",
      "        [1.6837],\n",
      "        [1.7607],\n",
      "        [1.6770],\n",
      "        [1.6950],\n",
      "        [1.7296],\n",
      "        [1.7236],\n",
      "        [1.7363],\n",
      "        [1.6813],\n",
      "        [1.7148],\n",
      "        [1.6901],\n",
      "        [1.7488],\n",
      "        [1.7078],\n",
      "        [1.6939],\n",
      "        [1.6981],\n",
      "        [1.7768],\n",
      "        [1.7103],\n",
      "        [1.7692],\n",
      "        [1.7655],\n",
      "        [1.7342],\n",
      "        [1.7638],\n",
      "        [1.7227],\n",
      "        [1.6820],\n",
      "        [1.7028],\n",
      "        [1.7841],\n",
      "        [1.7382],\n",
      "        [1.6778],\n",
      "        [1.7726],\n",
      "        [1.6630],\n",
      "        [1.7839],\n",
      "        [1.7110],\n",
      "        [1.6795],\n",
      "        [1.7783],\n",
      "        [1.7445],\n",
      "        [1.7249],\n",
      "        [1.7717],\n",
      "        [1.7117],\n",
      "        [1.6957],\n",
      "        [1.6752],\n",
      "        [1.7381],\n",
      "        [1.7525],\n",
      "        [1.7282],\n",
      "        [1.7024],\n",
      "        [1.6732],\n",
      "        [1.7735],\n",
      "        [1.7016],\n",
      "        [1.7166],\n",
      "        [1.6821],\n",
      "        [1.6855],\n",
      "        [1.6945],\n",
      "        [1.7345],\n",
      "        [1.6916],\n",
      "        [1.7206],\n",
      "        [1.7657],\n",
      "        [1.6898],\n",
      "        [1.6749],\n",
      "        [1.7707],\n",
      "        [1.6995],\n",
      "        [1.6671],\n",
      "        [1.6889],\n",
      "        [1.7658],\n",
      "        [1.7317],\n",
      "        [1.6976],\n",
      "        [1.7221],\n",
      "        [1.6988],\n",
      "        [1.7793],\n",
      "        [1.7179],\n",
      "        [1.6710],\n",
      "        [1.6650],\n",
      "        [1.7676],\n",
      "        [1.6805],\n",
      "        [1.6828],\n",
      "        [1.7374],\n",
      "        [1.7067],\n",
      "        [1.7113],\n",
      "        [1.7429],\n",
      "        [1.7302],\n",
      "        [1.6879],\n",
      "        [1.6870],\n",
      "        [1.6938],\n",
      "        [1.6934],\n",
      "        [1.7098],\n",
      "        [1.7251],\n",
      "        [1.6706],\n",
      "        [1.6693],\n",
      "        [1.6891],\n",
      "        [1.6937],\n",
      "        [1.7600],\n",
      "        [1.7716],\n",
      "        [1.7410],\n",
      "        [1.7203],\n",
      "        [1.6686],\n",
      "        [1.7356],\n",
      "        [1.6792],\n",
      "        [1.7018],\n",
      "        [1.6820],\n",
      "        [1.6740],\n",
      "        [1.6953],\n",
      "        [1.7812],\n",
      "        [1.7233],\n",
      "        [1.7052],\n",
      "        [1.7038],\n",
      "        [1.7513],\n",
      "        [1.7524],\n",
      "        [1.7020],\n",
      "        [1.6794],\n",
      "        [1.7625],\n",
      "        [1.7516],\n",
      "        [1.6881],\n",
      "        [1.7220],\n",
      "        [1.7266],\n",
      "        [1.6923],\n",
      "        [1.6733],\n",
      "        [1.7461],\n",
      "        [1.7504],\n",
      "        [1.7222],\n",
      "        [1.6786],\n",
      "        [1.7406],\n",
      "        [1.6743],\n",
      "        [1.6961],\n",
      "        [1.7233],\n",
      "        [1.6776],\n",
      "        [1.7055],\n",
      "        [1.7389],\n",
      "        [1.7764],\n",
      "        [1.7728],\n",
      "        [1.7462],\n",
      "        [1.7202],\n",
      "        [1.7230],\n",
      "        [1.6707],\n",
      "        [1.7221],\n",
      "        [1.6798],\n",
      "        [1.7267],\n",
      "        [1.7756],\n",
      "        [1.7624],\n",
      "        [1.7449],\n",
      "        [1.6926],\n",
      "        [1.7698],\n",
      "        [1.7727],\n",
      "        [1.7465],\n",
      "        [1.6824],\n",
      "        [1.7584],\n",
      "        [1.6806],\n",
      "        [1.6765],\n",
      "        [1.7094],\n",
      "        [1.7456],\n",
      "        [1.7344],\n",
      "        [1.7400],\n",
      "        [1.6948],\n",
      "        [1.7515],\n",
      "        [1.7326],\n",
      "        [1.6697],\n",
      "        [1.7454],\n",
      "        [1.7309],\n",
      "        [1.7597],\n",
      "        [1.6860],\n",
      "        [1.7211],\n",
      "        [1.7628],\n",
      "        [1.6782],\n",
      "        [1.7628],\n",
      "        [1.6706],\n",
      "        [1.7270],\n",
      "        [1.6750],\n",
      "        [1.7161],\n",
      "        [1.7663],\n",
      "        [1.7016],\n",
      "        [1.7432],\n",
      "        [1.7132],\n",
      "        [1.7229],\n",
      "        [1.6732],\n",
      "        [1.6889],\n",
      "        [1.7663],\n",
      "        [1.6809],\n",
      "        [1.6972],\n",
      "        [1.7351],\n",
      "        [1.7695],\n",
      "        [1.7784],\n",
      "        [1.7474],\n",
      "        [1.7260],\n",
      "        [1.6679],\n",
      "        [1.6838],\n",
      "        [1.6741],\n",
      "        [1.6891],\n",
      "        [1.7649],\n",
      "        [1.7150],\n",
      "        [1.6643],\n",
      "        [1.7838],\n",
      "        [1.7086],\n",
      "        [1.7605],\n",
      "        [1.6986],\n",
      "        [1.7268],\n",
      "        [1.7053],\n",
      "        [1.7541],\n",
      "        [1.7715],\n",
      "        [1.7826],\n",
      "        [1.7652],\n",
      "        [1.7308],\n",
      "        [1.6634],\n",
      "        [1.7744],\n",
      "        [1.6945],\n",
      "        [1.7592],\n",
      "        [1.7687],\n",
      "        [1.6745],\n",
      "        [1.7323],\n",
      "        [1.7752],\n",
      "        [1.7782],\n",
      "        [1.6987],\n",
      "        [1.7409],\n",
      "        [1.7423],\n",
      "        [1.7179],\n",
      "        [1.6832],\n",
      "        [1.6823],\n",
      "        [1.7224],\n",
      "        [1.7268],\n",
      "        [1.7000],\n",
      "        [1.7358],\n",
      "        [1.6842],\n",
      "        [1.7580],\n",
      "        [1.6673],\n",
      "        [1.6810],\n",
      "        [1.7489],\n",
      "        [1.7236],\n",
      "        [1.6758],\n",
      "        [1.7037],\n",
      "        [1.7063],\n",
      "        [1.6980],\n",
      "        [1.7321],\n",
      "        [1.7096],\n",
      "        [1.6836],\n",
      "        [1.7080],\n",
      "        [1.7179],\n",
      "        [1.7327],\n",
      "        [1.6832],\n",
      "        [1.6885],\n",
      "        [1.7542],\n",
      "        [1.7452],\n",
      "        [1.7450],\n",
      "        [1.6851],\n",
      "        [1.7385],\n",
      "        [1.7146],\n",
      "        [1.6734],\n",
      "        [1.7243],\n",
      "        [1.7066],\n",
      "        [1.7625],\n",
      "        [1.6755],\n",
      "        [1.7283],\n",
      "        [1.7004],\n",
      "        [1.7362],\n",
      "        [1.7220],\n",
      "        [1.7107],\n",
      "        [1.6869],\n",
      "        [1.6735],\n",
      "        [1.6779],\n",
      "        [1.7782],\n",
      "        [1.6690],\n",
      "        [1.7213],\n",
      "        [1.6845],\n",
      "        [1.6816],\n",
      "        [1.6935],\n",
      "        [1.7483],\n",
      "        [1.7091],\n",
      "        [1.7432],\n",
      "        [1.7141],\n",
      "        [1.6771],\n",
      "        [1.7234],\n",
      "        [1.7218],\n",
      "        [1.7775],\n",
      "        [1.6983],\n",
      "        [1.6773],\n",
      "        [1.7532],\n",
      "        [1.7330],\n",
      "        [1.6911],\n",
      "        [1.7321],\n",
      "        [1.6694],\n",
      "        [1.7652],\n",
      "        [1.7255],\n",
      "        [1.7235],\n",
      "        [1.7321],\n",
      "        [1.6771],\n",
      "        [1.7262],\n",
      "        [1.7351],\n",
      "        [1.7563],\n",
      "        [1.7163],\n",
      "        [1.7468],\n",
      "        [1.6712],\n",
      "        [1.7659],\n",
      "        [1.7543],\n",
      "        [1.7424],\n",
      "        [1.7558],\n",
      "        [1.6696],\n",
      "        [1.7116],\n",
      "        [1.7437],\n",
      "        [1.6946],\n",
      "        [1.7785],\n",
      "        [1.7547],\n",
      "        [1.6724],\n",
      "        [1.6670],\n",
      "        [1.7372],\n",
      "        [1.6959],\n",
      "        [1.7350],\n",
      "        [1.7674],\n",
      "        [1.7598],\n",
      "        [1.7464],\n",
      "        [1.7226],\n",
      "        [1.7473],\n",
      "        [1.7221],\n",
      "        [1.7317],\n",
      "        [1.7468],\n",
      "        [1.6795],\n",
      "        [1.6989],\n",
      "        [1.7422],\n",
      "        [1.6866],\n",
      "        [1.6715],\n",
      "        [1.7373],\n",
      "        [1.7760],\n",
      "        [1.7079],\n",
      "        [1.6772],\n",
      "        [1.7321],\n",
      "        [1.7551],\n",
      "        [1.7101],\n",
      "        [1.6723],\n",
      "        [1.6826],\n",
      "        [1.7438],\n",
      "        [1.7605],\n",
      "        [1.7205],\n",
      "        [1.7207],\n",
      "        [1.7633],\n",
      "        [1.6923],\n",
      "        [1.7496],\n",
      "        [1.6682],\n",
      "        [1.7743],\n",
      "        [1.7338],\n",
      "        [1.6840],\n",
      "        [1.7627],\n",
      "        [1.6796],\n",
      "        [1.6719],\n",
      "        [1.6723],\n",
      "        [1.7094],\n",
      "        [1.7392],\n",
      "        [1.7015],\n",
      "        [1.7533],\n",
      "        [1.6979],\n",
      "        [1.6830],\n",
      "        [1.7419],\n",
      "        [1.7797],\n",
      "        [1.7150],\n",
      "        [1.7193],\n",
      "        [1.7805],\n",
      "        [1.7146],\n",
      "        [1.7393],\n",
      "        [1.7497],\n",
      "        [1.6771],\n",
      "        [1.6809],\n",
      "        [1.7038],\n",
      "        [1.7225],\n",
      "        [1.7064],\n",
      "        [1.7614],\n",
      "        [1.7782],\n",
      "        [1.7239],\n",
      "        [1.7474],\n",
      "        [1.6680],\n",
      "        [1.6653],\n",
      "        [1.7005],\n",
      "        [1.7536],\n",
      "        [1.7267],\n",
      "        [1.6918],\n",
      "        [1.7495],\n",
      "        [1.7683],\n",
      "        [1.7373],\n",
      "        [1.6759],\n",
      "        [1.6758],\n",
      "        [1.7286],\n",
      "        [1.6911],\n",
      "        [1.7060],\n",
      "        [1.7285],\n",
      "        [1.7324],\n",
      "        [1.7238],\n",
      "        [1.7787],\n",
      "        [1.7212],\n",
      "        [1.6902],\n",
      "        [1.6750],\n",
      "        [1.6736],\n",
      "        [1.6899],\n",
      "        [1.7733],\n",
      "        [1.7434],\n",
      "        [1.6718],\n",
      "        [1.7374],\n",
      "        [1.7776],\n",
      "        [1.7146],\n",
      "        [1.7656],\n",
      "        [1.6869],\n",
      "        [1.7450],\n",
      "        [1.7010],\n",
      "        [1.7283],\n",
      "        [1.6693],\n",
      "        [1.7311],\n",
      "        [1.7831],\n",
      "        [1.6999],\n",
      "        [1.7234],\n",
      "        [1.6903],\n",
      "        [1.7115],\n",
      "        [1.7486],\n",
      "        [1.7623],\n",
      "        [1.6835],\n",
      "        [1.6962],\n",
      "        [1.7372]])\n",
      "sigma: tensor([[0.3195],\n",
      "        [0.3242],\n",
      "        [0.3342],\n",
      "        [0.3113],\n",
      "        [0.3107],\n",
      "        [0.3157],\n",
      "        [0.3054],\n",
      "        [0.3210],\n",
      "        [0.3106],\n",
      "        [0.3049],\n",
      "        [0.3304],\n",
      "        [0.3209],\n",
      "        [0.3110],\n",
      "        [0.3146],\n",
      "        [0.3110],\n",
      "        [0.3255],\n",
      "        [0.3240],\n",
      "        [0.3287],\n",
      "        [0.2981],\n",
      "        [0.3326],\n",
      "        [0.3175],\n",
      "        [0.3280],\n",
      "        [0.3121],\n",
      "        [0.3072],\n",
      "        [0.3253],\n",
      "        [0.2951],\n",
      "        [0.3124],\n",
      "        [0.3033],\n",
      "        [0.2944],\n",
      "        [0.3201],\n",
      "        [0.2955],\n",
      "        [0.3210],\n",
      "        [0.3108],\n",
      "        [0.3000],\n",
      "        [0.3271],\n",
      "        [0.2998],\n",
      "        [0.3191],\n",
      "        [0.3308],\n",
      "        [0.3188],\n",
      "        [0.3057],\n",
      "        [0.2978],\n",
      "        [0.3282],\n",
      "        [0.3246],\n",
      "        [0.3288],\n",
      "        [0.3046],\n",
      "        [0.3114],\n",
      "        [0.3066],\n",
      "        [0.3213],\n",
      "        [0.3291],\n",
      "        [0.3260],\n",
      "        [0.3102],\n",
      "        [0.3364],\n",
      "        [0.3205],\n",
      "        [0.3241],\n",
      "        [0.3192],\n",
      "        [0.3016],\n",
      "        [0.2943],\n",
      "        [0.3334],\n",
      "        [0.3100],\n",
      "        [0.3112],\n",
      "        [0.3342],\n",
      "        [0.3157],\n",
      "        [0.3217],\n",
      "        [0.3206],\n",
      "        [0.3262],\n",
      "        [0.3149],\n",
      "        [0.3108],\n",
      "        [0.3126],\n",
      "        [0.3223],\n",
      "        [0.3053],\n",
      "        [0.3098],\n",
      "        [0.3247],\n",
      "        [0.3123],\n",
      "        [0.3000],\n",
      "        [0.3158],\n",
      "        [0.3340],\n",
      "        [0.3328],\n",
      "        [0.3225],\n",
      "        [0.3349],\n",
      "        [0.3101],\n",
      "        [0.3314],\n",
      "        [0.2987],\n",
      "        [0.3183],\n",
      "        [0.3250],\n",
      "        [0.3135],\n",
      "        [0.3201],\n",
      "        [0.2910],\n",
      "        [0.3108],\n",
      "        [0.2967],\n",
      "        [0.3271],\n",
      "        [0.3374],\n",
      "        [0.3286],\n",
      "        [0.2987],\n",
      "        [0.3196],\n",
      "        [0.3355],\n",
      "        [0.3207],\n",
      "        [0.3047],\n",
      "        [0.2905],\n",
      "        [0.3271],\n",
      "        [0.3089],\n",
      "        [0.3076],\n",
      "        [0.3081],\n",
      "        [0.3261],\n",
      "        [0.3296],\n",
      "        [0.3261],\n",
      "        [0.2962],\n",
      "        [0.3172],\n",
      "        [0.3309],\n",
      "        [0.3236],\n",
      "        [0.3028],\n",
      "        [0.3107],\n",
      "        [0.3238],\n",
      "        [0.3100],\n",
      "        [0.2963],\n",
      "        [0.3039],\n",
      "        [0.3261],\n",
      "        [0.3230],\n",
      "        [0.3287],\n",
      "        [0.3181],\n",
      "        [0.3099],\n",
      "        [0.3193],\n",
      "        [0.3320],\n",
      "        [0.3203],\n",
      "        [0.2928],\n",
      "        [0.3141],\n",
      "        [0.3261],\n",
      "        [0.2982],\n",
      "        [0.3319],\n",
      "        [0.3029],\n",
      "        [0.3038],\n",
      "        [0.3311],\n",
      "        [0.2966],\n",
      "        [0.2992],\n",
      "        [0.3282],\n",
      "        [0.3282],\n",
      "        [0.3188],\n",
      "        [0.3299],\n",
      "        [0.3320],\n",
      "        [0.3254],\n",
      "        [0.3182],\n",
      "        [0.3322],\n",
      "        [0.2963],\n",
      "        [0.3351],\n",
      "        [0.3061],\n",
      "        [0.3112],\n",
      "        [0.2957],\n",
      "        [0.3326],\n",
      "        [0.3371],\n",
      "        [0.3249],\n",
      "        [0.3180],\n",
      "        [0.3108],\n",
      "        [0.3351],\n",
      "        [0.2943],\n",
      "        [0.3358],\n",
      "        [0.3039],\n",
      "        [0.2994],\n",
      "        [0.3140],\n",
      "        [0.3164],\n",
      "        [0.3314],\n",
      "        [0.3069],\n",
      "        [0.3190],\n",
      "        [0.3187],\n",
      "        [0.2914],\n",
      "        [0.3182],\n",
      "        [0.2929],\n",
      "        [0.3351],\n",
      "        [0.3003],\n",
      "        [0.3140],\n",
      "        [0.3305],\n",
      "        [0.3160],\n",
      "        [0.3119],\n",
      "        [0.2955],\n",
      "        [0.3210],\n",
      "        [0.2982],\n",
      "        [0.3182],\n",
      "        [0.2966],\n",
      "        [0.3146],\n",
      "        [0.2962],\n",
      "        [0.3144],\n",
      "        [0.3006],\n",
      "        [0.3140],\n",
      "        [0.3297],\n",
      "        [0.3155],\n",
      "        [0.3313],\n",
      "        [0.3162],\n",
      "        [0.3073],\n",
      "        [0.3279],\n",
      "        [0.3035],\n",
      "        [0.3322],\n",
      "        [0.3142],\n",
      "        [0.3276],\n",
      "        [0.2991],\n",
      "        [0.3010],\n",
      "        [0.3102],\n",
      "        [0.3034],\n",
      "        [0.3088],\n",
      "        [0.3308],\n",
      "        [0.3135],\n",
      "        [0.3353],\n",
      "        [0.3196],\n",
      "        [0.3085],\n",
      "        [0.3192],\n",
      "        [0.3342],\n",
      "        [0.3193],\n",
      "        [0.3340],\n",
      "        [0.3219],\n",
      "        [0.3347],\n",
      "        [0.2950],\n",
      "        [0.3078],\n",
      "        [0.3279],\n",
      "        [0.3003],\n",
      "        [0.3232],\n",
      "        [0.3284],\n",
      "        [0.3025],\n",
      "        [0.3117],\n",
      "        [0.3052],\n",
      "        [0.3210],\n",
      "        [0.2931],\n",
      "        [0.3001],\n",
      "        [0.3301],\n",
      "        [0.3331],\n",
      "        [0.3134],\n",
      "        [0.3080],\n",
      "        [0.3090],\n",
      "        [0.3259],\n",
      "        [0.2933],\n",
      "        [0.3154],\n",
      "        [0.3333],\n",
      "        [0.3231],\n",
      "        [0.3365],\n",
      "        [0.3086],\n",
      "        [0.3017],\n",
      "        [0.3281],\n",
      "        [0.3348],\n",
      "        [0.3315],\n",
      "        [0.3240],\n",
      "        [0.3234],\n",
      "        [0.3060],\n",
      "        [0.3326],\n",
      "        [0.2980],\n",
      "        [0.2996],\n",
      "        [0.3212],\n",
      "        [0.3051],\n",
      "        [0.3146],\n",
      "        [0.2913],\n",
      "        [0.3068],\n",
      "        [0.3079],\n",
      "        [0.2974],\n",
      "        [0.2944],\n",
      "        [0.3252],\n",
      "        [0.3053],\n",
      "        [0.2958],\n",
      "        [0.3360],\n",
      "        [0.3269],\n",
      "        [0.2973],\n",
      "        [0.3181],\n",
      "        [0.3077],\n",
      "        [0.2946],\n",
      "        [0.3074],\n",
      "        [0.2982],\n",
      "        [0.3254],\n",
      "        [0.3028],\n",
      "        [0.3313],\n",
      "        [0.3343],\n",
      "        [0.3025],\n",
      "        [0.3283],\n",
      "        [0.3207],\n",
      "        [0.3232],\n",
      "        [0.3229],\n",
      "        [0.3078],\n",
      "        [0.3160],\n",
      "        [0.2977],\n",
      "        [0.3246],\n",
      "        [0.3257],\n",
      "        [0.3327],\n",
      "        [0.3127],\n",
      "        [0.3278],\n",
      "        [0.3146],\n",
      "        [0.3135],\n",
      "        [0.3227],\n",
      "        [0.3329],\n",
      "        [0.2992],\n",
      "        [0.3263],\n",
      "        [0.3307],\n",
      "        [0.3169],\n",
      "        [0.3225],\n",
      "        [0.2984],\n",
      "        [0.3126],\n",
      "        [0.2915],\n",
      "        [0.3283],\n",
      "        [0.3346],\n",
      "        [0.3301],\n",
      "        [0.3041],\n",
      "        [0.3156],\n",
      "        [0.3331],\n",
      "        [0.3277],\n",
      "        [0.3313],\n",
      "        [0.3074],\n",
      "        [0.3262],\n",
      "        [0.2913],\n",
      "        [0.3342],\n",
      "        [0.2991],\n",
      "        [0.3211],\n",
      "        [0.3304],\n",
      "        [0.3149],\n",
      "        [0.3259],\n",
      "        [0.3011],\n",
      "        [0.3257],\n",
      "        [0.3325],\n",
      "        [0.3326],\n",
      "        [0.3256],\n",
      "        [0.3005],\n",
      "        [0.3213],\n",
      "        [0.2969],\n",
      "        [0.3168],\n",
      "        [0.2950],\n",
      "        [0.3271],\n",
      "        [0.3177],\n",
      "        [0.3103],\n",
      "        [0.3258],\n",
      "        [0.3024],\n",
      "        [0.3271],\n",
      "        [0.3204],\n",
      "        [0.3076],\n",
      "        [0.3202],\n",
      "        [0.2985],\n",
      "        [0.3062],\n",
      "        [0.3261],\n",
      "        [0.3247],\n",
      "        [0.3267],\n",
      "        [0.2996],\n",
      "        [0.3126],\n",
      "        [0.3050],\n",
      "        [0.3359],\n",
      "        [0.3273],\n",
      "        [0.3103],\n",
      "        [0.3131],\n",
      "        [0.3150],\n",
      "        [0.3120],\n",
      "        [0.3209],\n",
      "        [0.3063],\n",
      "        [0.3191],\n",
      "        [0.3009],\n",
      "        [0.3081],\n",
      "        [0.3289],\n",
      "        [0.3234],\n",
      "        [0.2979],\n",
      "        [0.3178],\n",
      "        [0.3173],\n",
      "        [0.3090],\n",
      "        [0.3313],\n",
      "        [0.2984],\n",
      "        [0.3188],\n",
      "        [0.3262],\n",
      "        [0.2989],\n",
      "        [0.3256],\n",
      "        [0.3361],\n",
      "        [0.3315],\n",
      "        [0.3185],\n",
      "        [0.2931],\n",
      "        [0.2983],\n",
      "        [0.3082],\n",
      "        [0.3207],\n",
      "        [0.3299],\n",
      "        [0.3183],\n",
      "        [0.3294],\n",
      "        [0.3058],\n",
      "        [0.3049],\n",
      "        [0.3311],\n",
      "        [0.3224],\n",
      "        [0.3256],\n",
      "        [0.3066],\n",
      "        [0.3222],\n",
      "        [0.2913],\n",
      "        [0.3057],\n",
      "        [0.3211],\n",
      "        [0.3200],\n",
      "        [0.3308],\n",
      "        [0.3279],\n",
      "        [0.3226],\n",
      "        [0.3343],\n",
      "        [0.3335],\n",
      "        [0.2983],\n",
      "        [0.3039],\n",
      "        [0.3285],\n",
      "        [0.3129],\n",
      "        [0.3208],\n",
      "        [0.3120],\n",
      "        [0.3355],\n",
      "        [0.3073],\n",
      "        [0.3208],\n",
      "        [0.3112],\n",
      "        [0.3095],\n",
      "        [0.3022],\n",
      "        [0.3303],\n",
      "        [0.2951],\n",
      "        [0.3262],\n",
      "        [0.3118],\n",
      "        [0.3023],\n",
      "        [0.3229],\n",
      "        [0.3122],\n",
      "        [0.3227],\n",
      "        [0.3212],\n",
      "        [0.3053],\n",
      "        [0.3032],\n",
      "        [0.3143],\n",
      "        [0.3131],\n",
      "        [0.2986],\n",
      "        [0.3264],\n",
      "        [0.3316],\n",
      "        [0.3282],\n",
      "        [0.2969],\n",
      "        [0.3226],\n",
      "        [0.3257],\n",
      "        [0.3353],\n",
      "        [0.2969],\n",
      "        [0.3016],\n",
      "        [0.3123],\n",
      "        [0.3227],\n",
      "        [0.3248],\n",
      "        [0.3027],\n",
      "        [0.3187],\n",
      "        [0.3332],\n",
      "        [0.3195],\n",
      "        [0.3300],\n",
      "        [0.3192],\n",
      "        [0.3056],\n",
      "        [0.3220],\n",
      "        [0.3143],\n",
      "        [0.3238],\n",
      "        [0.3078],\n",
      "        [0.3242],\n",
      "        [0.3039],\n",
      "        [0.3333],\n",
      "        [0.3342],\n",
      "        [0.3363],\n",
      "        [0.3243],\n",
      "        [0.3336],\n",
      "        [0.3248],\n",
      "        [0.3339],\n",
      "        [0.3161],\n",
      "        [0.3020],\n",
      "        [0.3261],\n",
      "        [0.3164],\n",
      "        [0.3171],\n",
      "        [0.3047],\n",
      "        [0.3348],\n",
      "        [0.3233],\n",
      "        [0.3135],\n",
      "        [0.2977],\n",
      "        [0.3013],\n",
      "        [0.3146],\n",
      "        [0.3290],\n",
      "        [0.3093],\n",
      "        [0.3230],\n",
      "        [0.3254],\n",
      "        [0.3309],\n",
      "        [0.3216],\n",
      "        [0.3364],\n",
      "        [0.3216],\n",
      "        [0.3202],\n",
      "        [0.3109],\n",
      "        [0.3008],\n",
      "        [0.2951],\n",
      "        [0.3043],\n",
      "        [0.3009],\n",
      "        [0.3069],\n",
      "        [0.3045],\n",
      "        [0.3110],\n",
      "        [0.3041],\n",
      "        [0.3219],\n",
      "        [0.3150],\n",
      "        [0.3247],\n",
      "        [0.3148],\n",
      "        [0.3249],\n",
      "        [0.3104],\n",
      "        [0.3104],\n",
      "        [0.3159],\n",
      "        [0.3258],\n",
      "        [0.3342],\n",
      "        [0.2920],\n",
      "        [0.3020],\n",
      "        [0.3296],\n",
      "        [0.3239],\n",
      "        [0.2923],\n",
      "        [0.3101],\n",
      "        [0.2991],\n",
      "        [0.3229],\n",
      "        [0.3157],\n",
      "        [0.3194],\n",
      "        [0.3172],\n",
      "        [0.3084],\n",
      "        [0.3207],\n",
      "        [0.3235],\n",
      "        [0.3280],\n",
      "        [0.3226],\n",
      "        [0.2949],\n",
      "        [0.3342],\n",
      "        [0.3071],\n",
      "        [0.3038],\n",
      "        [0.3212],\n",
      "        [0.3207],\n",
      "        [0.3363],\n",
      "        [0.2924],\n",
      "        [0.3274],\n",
      "        [0.2955],\n",
      "        [0.3056],\n",
      "        [0.2919],\n",
      "        [0.2987],\n",
      "        [0.3041],\n",
      "        [0.3157],\n",
      "        [0.2975],\n",
      "        [0.3345],\n",
      "        [0.3049],\n",
      "        [0.3035],\n",
      "        [0.3258],\n",
      "        [0.3134],\n",
      "        [0.3203],\n",
      "        [0.3032],\n",
      "        [0.3084],\n",
      "        [0.3005],\n",
      "        [0.3239],\n",
      "        [0.2935],\n",
      "        [0.3061],\n",
      "        [0.3224],\n",
      "        [0.2974],\n",
      "        [0.3034],\n",
      "        [0.3323],\n",
      "        [0.3231],\n",
      "        [0.3022],\n",
      "        [0.3310],\n",
      "        [0.3189],\n",
      "        [0.2957],\n",
      "        [0.2963],\n",
      "        [0.3098],\n",
      "        [0.3161],\n",
      "        [0.3212],\n",
      "        [0.3294],\n",
      "        [0.3015],\n",
      "        [0.3184],\n",
      "        [0.2950],\n",
      "        [0.3013],\n",
      "        [0.3154],\n",
      "        [0.3188],\n",
      "        [0.3258],\n",
      "        [0.3003],\n",
      "        [0.3171],\n",
      "        [0.3278],\n",
      "        [0.2960],\n",
      "        [0.3316],\n",
      "        [0.3039],\n",
      "        [0.3023],\n",
      "        [0.3273],\n",
      "        [0.2985],\n",
      "        [0.3044],\n",
      "        [0.2915],\n",
      "        [0.2988],\n",
      "        [0.2953],\n",
      "        [0.3219],\n",
      "        [0.3035],\n",
      "        [0.3210],\n",
      "        [0.3252],\n",
      "        [0.3205],\n",
      "        [0.3366],\n",
      "        [0.3010],\n",
      "        [0.3176],\n",
      "        [0.3219],\n",
      "        [0.3131],\n",
      "        [0.3159],\n",
      "        [0.3221],\n",
      "        [0.3203],\n",
      "        [0.3372],\n",
      "        [0.3316],\n",
      "        [0.3213],\n",
      "        [0.3026],\n",
      "        [0.2930],\n",
      "        [0.3174],\n",
      "        [0.3180],\n",
      "        [0.3000],\n",
      "        [0.3355],\n",
      "        [0.3355],\n",
      "        [0.3186],\n",
      "        [0.3158],\n",
      "        [0.3345],\n",
      "        [0.3225],\n",
      "        [0.2975],\n",
      "        [0.3151],\n",
      "        [0.3115],\n",
      "        [0.3077],\n",
      "        [0.3018],\n",
      "        [0.3158],\n",
      "        [0.3039],\n",
      "        [0.3355],\n",
      "        [0.3199],\n",
      "        [0.2930],\n",
      "        [0.3291],\n",
      "        [0.2996],\n",
      "        [0.3317],\n",
      "        [0.3247],\n",
      "        [0.3112],\n",
      "        [0.3135],\n",
      "        [0.3087],\n",
      "        [0.3301],\n",
      "        [0.3168],\n",
      "        [0.3266],\n",
      "        [0.3040],\n",
      "        [0.3196],\n",
      "        [0.3250],\n",
      "        [0.3234],\n",
      "        [0.2939],\n",
      "        [0.3186],\n",
      "        [0.2966],\n",
      "        [0.2979],\n",
      "        [0.3094],\n",
      "        [0.2986],\n",
      "        [0.3138],\n",
      "        [0.3298],\n",
      "        [0.3215],\n",
      "        [0.2913],\n",
      "        [0.3079],\n",
      "        [0.3315],\n",
      "        [0.2954],\n",
      "        [0.3376],\n",
      "        [0.2913],\n",
      "        [0.3184],\n",
      "        [0.3309],\n",
      "        [0.2933],\n",
      "        [0.3057],\n",
      "        [0.3131],\n",
      "        [0.2957],\n",
      "        [0.3181],\n",
      "        [0.3244],\n",
      "        [0.3326],\n",
      "        [0.3080],\n",
      "        [0.3027],\n",
      "        [0.3118],\n",
      "        [0.3217],\n",
      "        [0.3334],\n",
      "        [0.2950],\n",
      "        [0.3221],\n",
      "        [0.3162],\n",
      "        [0.3299],\n",
      "        [0.3284],\n",
      "        [0.3249],\n",
      "        [0.3094],\n",
      "        [0.3260],\n",
      "        [0.3146],\n",
      "        [0.2978],\n",
      "        [0.3266],\n",
      "        [0.3327],\n",
      "        [0.2960],\n",
      "        [0.3228],\n",
      "        [0.3359],\n",
      "        [0.3271],\n",
      "        [0.2978],\n",
      "        [0.3104],\n",
      "        [0.3236],\n",
      "        [0.3141],\n",
      "        [0.3231],\n",
      "        [0.2930],\n",
      "        [0.3157],\n",
      "        [0.3344],\n",
      "        [0.3368],\n",
      "        [0.2972],\n",
      "        [0.3305],\n",
      "        [0.3295],\n",
      "        [0.3083],\n",
      "        [0.3200],\n",
      "        [0.3181],\n",
      "        [0.3062],\n",
      "        [0.3110],\n",
      "        [0.3274],\n",
      "        [0.3279],\n",
      "        [0.3250],\n",
      "        [0.3253],\n",
      "        [0.3189],\n",
      "        [0.3130],\n",
      "        [0.3344],\n",
      "        [0.3350],\n",
      "        [0.3269],\n",
      "        [0.3251],\n",
      "        [0.2999],\n",
      "        [0.2957],\n",
      "        [0.3070],\n",
      "        [0.3147],\n",
      "        [0.3353],\n",
      "        [0.3090],\n",
      "        [0.3309],\n",
      "        [0.3220],\n",
      "        [0.3297],\n",
      "        [0.3331],\n",
      "        [0.3246],\n",
      "        [0.2923],\n",
      "        [0.3136],\n",
      "        [0.3206],\n",
      "        [0.3212],\n",
      "        [0.3031],\n",
      "        [0.3027],\n",
      "        [0.3218],\n",
      "        [0.3308],\n",
      "        [0.2990],\n",
      "        [0.3030],\n",
      "        [0.3274],\n",
      "        [0.3141],\n",
      "        [0.3124],\n",
      "        [0.3257],\n",
      "        [0.3334],\n",
      "        [0.3050],\n",
      "        [0.3034],\n",
      "        [0.3141],\n",
      "        [0.3311],\n",
      "        [0.3071],\n",
      "        [0.3330],\n",
      "        [0.3242],\n",
      "        [0.3136],\n",
      "        [0.3315],\n",
      "        [0.3205],\n",
      "        [0.3077],\n",
      "        [0.2940],\n",
      "        [0.2953],\n",
      "        [0.3050],\n",
      "        [0.3148],\n",
      "        [0.3137],\n",
      "        [0.3344],\n",
      "        [0.3140],\n",
      "        [0.3307],\n",
      "        [0.3123],\n",
      "        [0.2943],\n",
      "        [0.2991],\n",
      "        [0.3054],\n",
      "        [0.3256],\n",
      "        [0.2964],\n",
      "        [0.2953],\n",
      "        [0.3049],\n",
      "        [0.3297],\n",
      "        [0.3005],\n",
      "        [0.3304],\n",
      "        [0.3321],\n",
      "        [0.3189],\n",
      "        [0.3052],\n",
      "        [0.3094],\n",
      "        [0.3073],\n",
      "        [0.3247],\n",
      "        [0.3031],\n",
      "        [0.3101],\n",
      "        [0.3348],\n",
      "        [0.3053],\n",
      "        [0.3108],\n",
      "        [0.3000],\n",
      "        [0.3282],\n",
      "        [0.3145],\n",
      "        [0.2989],\n",
      "        [0.3314],\n",
      "        [0.2989],\n",
      "        [0.3345],\n",
      "        [0.3122],\n",
      "        [0.3326],\n",
      "        [0.3164],\n",
      "        [0.2976],\n",
      "        [0.3221],\n",
      "        [0.3061],\n",
      "        [0.3175],\n",
      "        [0.3138],\n",
      "        [0.3334],\n",
      "        [0.3271],\n",
      "        [0.2976],\n",
      "        [0.3302],\n",
      "        [0.3237],\n",
      "        [0.3092],\n",
      "        [0.2965],\n",
      "        [0.2933],\n",
      "        [0.3046],\n",
      "        [0.3126],\n",
      "        [0.3355],\n",
      "        [0.3292],\n",
      "        [0.3331],\n",
      "        [0.3270],\n",
      "        [0.2981],\n",
      "        [0.3168],\n",
      "        [0.3371],\n",
      "        [0.2914],\n",
      "        [0.3192],\n",
      "        [0.2998],\n",
      "        [0.3231],\n",
      "        [0.3122],\n",
      "        [0.3205],\n",
      "        [0.3020],\n",
      "        [0.2958],\n",
      "        [0.2918],\n",
      "        [0.2980],\n",
      "        [0.3108],\n",
      "        [0.3375],\n",
      "        [0.2947],\n",
      "        [0.3248],\n",
      "        [0.3002],\n",
      "        [0.2967],\n",
      "        [0.3329],\n",
      "        [0.3102],\n",
      "        [0.2944],\n",
      "        [0.2934],\n",
      "        [0.3231],\n",
      "        [0.3070],\n",
      "        [0.3065],\n",
      "        [0.3158],\n",
      "        [0.3293],\n",
      "        [0.3297],\n",
      "        [0.3140],\n",
      "        [0.3123],\n",
      "        [0.3226],\n",
      "        [0.3089],\n",
      "        [0.3290],\n",
      "        [0.3006],\n",
      "        [0.3358],\n",
      "        [0.3302],\n",
      "        [0.3040],\n",
      "        [0.3135],\n",
      "        [0.3324],\n",
      "        [0.3212],\n",
      "        [0.3202],\n",
      "        [0.3234],\n",
      "        [0.3102],\n",
      "        [0.3189],\n",
      "        [0.3293],\n",
      "        [0.3196],\n",
      "        [0.3157],\n",
      "        [0.3100],\n",
      "        [0.3293],\n",
      "        [0.3272],\n",
      "        [0.3020],\n",
      "        [0.3053],\n",
      "        [0.3054],\n",
      "        [0.3286],\n",
      "        [0.3079],\n",
      "        [0.3169],\n",
      "        [0.3333],\n",
      "        [0.3132],\n",
      "        [0.3201],\n",
      "        [0.2990],\n",
      "        [0.3325],\n",
      "        [0.3117],\n",
      "        [0.3225],\n",
      "        [0.3088],\n",
      "        [0.3142],\n",
      "        [0.3184],\n",
      "        [0.3278],\n",
      "        [0.3334],\n",
      "        [0.3315],\n",
      "        [0.2934],\n",
      "        [0.3351],\n",
      "        [0.3144],\n",
      "        [0.3288],\n",
      "        [0.3299],\n",
      "        [0.3253],\n",
      "        [0.3042],\n",
      "        [0.3191],\n",
      "        [0.3061],\n",
      "        [0.3171],\n",
      "        [0.3318],\n",
      "        [0.3136],\n",
      "        [0.3142],\n",
      "        [0.2936],\n",
      "        [0.3234],\n",
      "        [0.3318],\n",
      "        [0.3024],\n",
      "        [0.3100],\n",
      "        [0.3262],\n",
      "        [0.3103],\n",
      "        [0.3349],\n",
      "        [0.2980],\n",
      "        [0.3128],\n",
      "        [0.3136],\n",
      "        [0.3103],\n",
      "        [0.3317],\n",
      "        [0.3125],\n",
      "        [0.3092],\n",
      "        [0.3012],\n",
      "        [0.3163],\n",
      "        [0.3048],\n",
      "        [0.3342],\n",
      "        [0.2978],\n",
      "        [0.3020],\n",
      "        [0.3064],\n",
      "        [0.3015],\n",
      "        [0.3349],\n",
      "        [0.3181],\n",
      "        [0.3059],\n",
      "        [0.3248],\n",
      "        [0.2933],\n",
      "        [0.3019],\n",
      "        [0.3338],\n",
      "        [0.3360],\n",
      "        [0.3084],\n",
      "        [0.3242],\n",
      "        [0.3092],\n",
      "        [0.2972],\n",
      "        [0.3000],\n",
      "        [0.3049],\n",
      "        [0.3138],\n",
      "        [0.3046],\n",
      "        [0.3141],\n",
      "        [0.3104],\n",
      "        [0.3048],\n",
      "        [0.3308],\n",
      "        [0.3231],\n",
      "        [0.3065],\n",
      "        [0.3280],\n",
      "        [0.3341],\n",
      "        [0.3083],\n",
      "        [0.2941],\n",
      "        [0.3196],\n",
      "        [0.3318],\n",
      "        [0.3103],\n",
      "        [0.3017],\n",
      "        [0.3188],\n",
      "        [0.3337],\n",
      "        [0.3296],\n",
      "        [0.3059],\n",
      "        [0.2997],\n",
      "        [0.3146],\n",
      "        [0.3146],\n",
      "        [0.2987],\n",
      "        [0.3257],\n",
      "        [0.3037],\n",
      "        [0.3354],\n",
      "        [0.2948],\n",
      "        [0.3096],\n",
      "        [0.3290],\n",
      "        [0.2989],\n",
      "        [0.3308],\n",
      "        [0.3339],\n",
      "        [0.3338],\n",
      "        [0.3189],\n",
      "        [0.3076],\n",
      "        [0.3220],\n",
      "        [0.3024],\n",
      "        [0.3235],\n",
      "        [0.3294],\n",
      "        [0.3066],\n",
      "        [0.2928],\n",
      "        [0.3169],\n",
      "        [0.3152],\n",
      "        [0.2925],\n",
      "        [0.3170],\n",
      "        [0.3076],\n",
      "        [0.3037],\n",
      "        [0.3318],\n",
      "        [0.3303],\n",
      "        [0.3212],\n",
      "        [0.3140],\n",
      "        [0.3202],\n",
      "        [0.2994],\n",
      "        [0.2934],\n",
      "        [0.3134],\n",
      "        [0.3046],\n",
      "        [0.3356],\n",
      "        [0.3367],\n",
      "        [0.3225],\n",
      "        [0.3023],\n",
      "        [0.3123],\n",
      "        [0.3259],\n",
      "        [0.3038],\n",
      "        [0.2969],\n",
      "        [0.3083],\n",
      "        [0.3323],\n",
      "        [0.3323],\n",
      "        [0.3115],\n",
      "        [0.3261],\n",
      "        [0.3203],\n",
      "        [0.3116],\n",
      "        [0.3102],\n",
      "        [0.3134],\n",
      "        [0.2932],\n",
      "        [0.3144],\n",
      "        [0.3265],\n",
      "        [0.3326],\n",
      "        [0.3332],\n",
      "        [0.3266],\n",
      "        [0.2951],\n",
      "        [0.3061],\n",
      "        [0.3340],\n",
      "        [0.3083],\n",
      "        [0.2936],\n",
      "        [0.3170],\n",
      "        [0.2979],\n",
      "        [0.3279],\n",
      "        [0.3055],\n",
      "        [0.3223],\n",
      "        [0.3117],\n",
      "        [0.3349],\n",
      "        [0.3107],\n",
      "        [0.2916],\n",
      "        [0.3227],\n",
      "        [0.3136],\n",
      "        [0.3266],\n",
      "        [0.3182],\n",
      "        [0.3041],\n",
      "        [0.2991],\n",
      "        [0.3292],\n",
      "        [0.3241],\n",
      "        [0.3083]])\n",
      "axr: tensor([[0.3963],\n",
      "        [0.4008],\n",
      "        [0.4103],\n",
      "        [0.3885],\n",
      "        [0.3879],\n",
      "        [0.3927],\n",
      "        [0.3828],\n",
      "        [0.3977],\n",
      "        [0.3879],\n",
      "        [0.3824],\n",
      "        [0.4067],\n",
      "        [0.3976],\n",
      "        [0.3882],\n",
      "        [0.3917],\n",
      "        [0.3883],\n",
      "        [0.4021],\n",
      "        [0.4006],\n",
      "        [0.4052],\n",
      "        [0.3758],\n",
      "        [0.4087],\n",
      "        [0.3944],\n",
      "        [0.4044],\n",
      "        [0.3893],\n",
      "        [0.3846],\n",
      "        [0.4019],\n",
      "        [0.3729],\n",
      "        [0.3896],\n",
      "        [0.3808],\n",
      "        [0.3722],\n",
      "        [0.3969],\n",
      "        [0.3734],\n",
      "        [0.3977],\n",
      "        [0.3881],\n",
      "        [0.3777],\n",
      "        [0.4036],\n",
      "        [0.3774],\n",
      "        [0.3960],\n",
      "        [0.4071],\n",
      "        [0.3957],\n",
      "        [0.3832],\n",
      "        [0.3756],\n",
      "        [0.4045],\n",
      "        [0.4012],\n",
      "        [0.4051],\n",
      "        [0.3821],\n",
      "        [0.3884],\n",
      "        [0.3840],\n",
      "        [0.3981],\n",
      "        [0.4055],\n",
      "        [0.4025],\n",
      "        [0.3875],\n",
      "        [0.4123],\n",
      "        [0.3973],\n",
      "        [0.4008],\n",
      "        [0.3960],\n",
      "        [0.3793],\n",
      "        [0.3722],\n",
      "        [0.4095],\n",
      "        [0.3873],\n",
      "        [0.3884],\n",
      "        [0.4102],\n",
      "        [0.3928],\n",
      "        [0.3984],\n",
      "        [0.3975],\n",
      "        [0.4027],\n",
      "        [0.3919],\n",
      "        [0.3880],\n",
      "        [0.3897],\n",
      "        [0.3990],\n",
      "        [0.3828],\n",
      "        [0.3871],\n",
      "        [0.4013],\n",
      "        [0.3895],\n",
      "        [0.3776],\n",
      "        [0.3928],\n",
      "        [0.4101],\n",
      "        [0.4089],\n",
      "        [0.3993],\n",
      "        [0.4110],\n",
      "        [0.3873],\n",
      "        [0.4076],\n",
      "        [0.3764],\n",
      "        [0.3952],\n",
      "        [0.4016],\n",
      "        [0.3907],\n",
      "        [0.3969],\n",
      "        [0.3690],\n",
      "        [0.3880],\n",
      "        [0.3745],\n",
      "        [0.4036],\n",
      "        [0.4133],\n",
      "        [0.4049],\n",
      "        [0.3765],\n",
      "        [0.3964],\n",
      "        [0.4115],\n",
      "        [0.3975],\n",
      "        [0.3822],\n",
      "        [0.3685],\n",
      "        [0.4035],\n",
      "        [0.3862],\n",
      "        [0.3850],\n",
      "        [0.3855],\n",
      "        [0.4026],\n",
      "        [0.4059],\n",
      "        [0.4026],\n",
      "        [0.3740],\n",
      "        [0.3942],\n",
      "        [0.4072],\n",
      "        [0.4003],\n",
      "        [0.3804],\n",
      "        [0.3879],\n",
      "        [0.4004],\n",
      "        [0.3873],\n",
      "        [0.3741],\n",
      "        [0.3814],\n",
      "        [0.4026],\n",
      "        [0.3997],\n",
      "        [0.4051],\n",
      "        [0.3950],\n",
      "        [0.3872],\n",
      "        [0.3962],\n",
      "        [0.4082],\n",
      "        [0.3972],\n",
      "        [0.3707],\n",
      "        [0.3912],\n",
      "        [0.4026],\n",
      "        [0.3759],\n",
      "        [0.4081],\n",
      "        [0.3805],\n",
      "        [0.3813],\n",
      "        [0.4074],\n",
      "        [0.3744],\n",
      "        [0.3769],\n",
      "        [0.4046],\n",
      "        [0.4046],\n",
      "        [0.3957],\n",
      "        [0.4062],\n",
      "        [0.4082],\n",
      "        [0.4019],\n",
      "        [0.3952],\n",
      "        [0.4083],\n",
      "        [0.3741],\n",
      "        [0.4110],\n",
      "        [0.3835],\n",
      "        [0.3884],\n",
      "        [0.3735],\n",
      "        [0.4088],\n",
      "        [0.4130],\n",
      "        [0.4015],\n",
      "        [0.3950],\n",
      "        [0.3881],\n",
      "        [0.4111],\n",
      "        [0.3721],\n",
      "        [0.4118],\n",
      "        [0.3814],\n",
      "        [0.3771],\n",
      "        [0.3912],\n",
      "        [0.3934],\n",
      "        [0.4077],\n",
      "        [0.3843],\n",
      "        [0.3958],\n",
      "        [0.3956],\n",
      "        [0.3694],\n",
      "        [0.3951],\n",
      "        [0.3708],\n",
      "        [0.4111],\n",
      "        [0.3780],\n",
      "        [0.3911],\n",
      "        [0.4067],\n",
      "        [0.3931],\n",
      "        [0.3891],\n",
      "        [0.3733],\n",
      "        [0.3978],\n",
      "        [0.3760],\n",
      "        [0.3951],\n",
      "        [0.3744],\n",
      "        [0.3917],\n",
      "        [0.3740],\n",
      "        [0.3915],\n",
      "        [0.3782],\n",
      "        [0.3911],\n",
      "        [0.4061],\n",
      "        [0.3926],\n",
      "        [0.4076],\n",
      "        [0.3932],\n",
      "        [0.3847],\n",
      "        [0.4044],\n",
      "        [0.3811],\n",
      "        [0.4084],\n",
      "        [0.3912],\n",
      "        [0.4041],\n",
      "        [0.3769],\n",
      "        [0.3786],\n",
      "        [0.3874],\n",
      "        [0.3809],\n",
      "        [0.3862],\n",
      "        [0.4071],\n",
      "        [0.3906],\n",
      "        [0.4113],\n",
      "        [0.3964],\n",
      "        [0.3858],\n",
      "        [0.3961],\n",
      "        [0.4102],\n",
      "        [0.3961],\n",
      "        [0.4101],\n",
      "        [0.3987],\n",
      "        [0.4107],\n",
      "        [0.3728],\n",
      "        [0.3852],\n",
      "        [0.4044],\n",
      "        [0.3779],\n",
      "        [0.3998],\n",
      "        [0.4048],\n",
      "        [0.3801],\n",
      "        [0.3889],\n",
      "        [0.3827],\n",
      "        [0.3978],\n",
      "        [0.3710],\n",
      "        [0.3778],\n",
      "        [0.4064],\n",
      "        [0.4093],\n",
      "        [0.3906],\n",
      "        [0.3854],\n",
      "        [0.3863],\n",
      "        [0.4024],\n",
      "        [0.3712],\n",
      "        [0.3925],\n",
      "        [0.4094],\n",
      "        [0.3998],\n",
      "        [0.4124],\n",
      "        [0.3860],\n",
      "        [0.3793],\n",
      "        [0.4045],\n",
      "        [0.4108],\n",
      "        [0.4077],\n",
      "        [0.4006],\n",
      "        [0.4001],\n",
      "        [0.3835],\n",
      "        [0.4088],\n",
      "        [0.3758],\n",
      "        [0.3773],\n",
      "        [0.3979],\n",
      "        [0.3826],\n",
      "        [0.3917],\n",
      "        [0.3693],\n",
      "        [0.3843],\n",
      "        [0.3853],\n",
      "        [0.3751],\n",
      "        [0.3723],\n",
      "        [0.4018],\n",
      "        [0.3827],\n",
      "        [0.3736],\n",
      "        [0.4120],\n",
      "        [0.4034],\n",
      "        [0.3751],\n",
      "        [0.3951],\n",
      "        [0.3851],\n",
      "        [0.3725],\n",
      "        [0.3848],\n",
      "        [0.3760],\n",
      "        [0.4020],\n",
      "        [0.3804],\n",
      "        [0.4076],\n",
      "        [0.4104],\n",
      "        [0.3801],\n",
      "        [0.4047],\n",
      "        [0.3975],\n",
      "        [0.3999],\n",
      "        [0.3995],\n",
      "        [0.3852],\n",
      "        [0.3930],\n",
      "        [0.3755],\n",
      "        [0.4012],\n",
      "        [0.4022],\n",
      "        [0.4088],\n",
      "        [0.3899],\n",
      "        [0.4042],\n",
      "        [0.3917],\n",
      "        [0.3907],\n",
      "        [0.3994],\n",
      "        [0.4090],\n",
      "        [0.3769],\n",
      "        [0.4028],\n",
      "        [0.4070],\n",
      "        [0.3939],\n",
      "        [0.3992],\n",
      "        [0.3761],\n",
      "        [0.3898],\n",
      "        [0.3694],\n",
      "        [0.4047],\n",
      "        [0.4106],\n",
      "        [0.4064],\n",
      "        [0.3816],\n",
      "        [0.3926],\n",
      "        [0.4092],\n",
      "        [0.4041],\n",
      "        [0.4075],\n",
      "        [0.3847],\n",
      "        [0.4028],\n",
      "        [0.3692],\n",
      "        [0.4103],\n",
      "        [0.3768],\n",
      "        [0.3978],\n",
      "        [0.4067],\n",
      "        [0.3919],\n",
      "        [0.4024],\n",
      "        [0.3787],\n",
      "        [0.4023],\n",
      "        [0.4087],\n",
      "        [0.4088],\n",
      "        [0.4022],\n",
      "        [0.3781],\n",
      "        [0.3981],\n",
      "        [0.3747],\n",
      "        [0.3937],\n",
      "        [0.3728],\n",
      "        [0.4036],\n",
      "        [0.3947],\n",
      "        [0.3876],\n",
      "        [0.4023],\n",
      "        [0.3800],\n",
      "        [0.4036],\n",
      "        [0.3972],\n",
      "        [0.3850],\n",
      "        [0.3971],\n",
      "        [0.3762],\n",
      "        [0.3836],\n",
      "        [0.4026],\n",
      "        [0.4013],\n",
      "        [0.4032],\n",
      "        [0.3773],\n",
      "        [0.3898],\n",
      "        [0.3825],\n",
      "        [0.4119],\n",
      "        [0.4037],\n",
      "        [0.3875],\n",
      "        [0.3902],\n",
      "        [0.3921],\n",
      "        [0.3892],\n",
      "        [0.3976],\n",
      "        [0.3837],\n",
      "        [0.3960],\n",
      "        [0.3786],\n",
      "        [0.3855],\n",
      "        [0.4052],\n",
      "        [0.4001],\n",
      "        [0.3756],\n",
      "        [0.3947],\n",
      "        [0.3943],\n",
      "        [0.3863],\n",
      "        [0.4075],\n",
      "        [0.3762],\n",
      "        [0.3957],\n",
      "        [0.4027],\n",
      "        [0.3766],\n",
      "        [0.4022],\n",
      "        [0.4121],\n",
      "        [0.4077],\n",
      "        [0.3954],\n",
      "        [0.3710],\n",
      "        [0.3760],\n",
      "        [0.3856],\n",
      "        [0.3974],\n",
      "        [0.4062],\n",
      "        [0.3952],\n",
      "        [0.4057],\n",
      "        [0.3833],\n",
      "        [0.3823],\n",
      "        [0.4074],\n",
      "        [0.3991],\n",
      "        [0.4022],\n",
      "        [0.3840],\n",
      "        [0.3989],\n",
      "        [0.3693],\n",
      "        [0.3831],\n",
      "        [0.3979],\n",
      "        [0.3968],\n",
      "        [0.4070],\n",
      "        [0.4043],\n",
      "        [0.3993],\n",
      "        [0.4103],\n",
      "        [0.4096],\n",
      "        [0.3760],\n",
      "        [0.3814],\n",
      "        [0.4049],\n",
      "        [0.3900],\n",
      "        [0.3976],\n",
      "        [0.3892],\n",
      "        [0.4115],\n",
      "        [0.3847],\n",
      "        [0.3976],\n",
      "        [0.3884],\n",
      "        [0.3868],\n",
      "        [0.3798],\n",
      "        [0.4065],\n",
      "        [0.3730],\n",
      "        [0.4027],\n",
      "        [0.3890],\n",
      "        [0.3799],\n",
      "        [0.3995],\n",
      "        [0.3894],\n",
      "        [0.3992],\n",
      "        [0.3980],\n",
      "        [0.3828],\n",
      "        [0.3808],\n",
      "        [0.3915],\n",
      "        [0.3903],\n",
      "        [0.3763],\n",
      "        [0.4029],\n",
      "        [0.4078],\n",
      "        [0.4046],\n",
      "        [0.3747],\n",
      "        [0.3993],\n",
      "        [0.4022],\n",
      "        [0.4113],\n",
      "        [0.3747],\n",
      "        [0.3792],\n",
      "        [0.3895],\n",
      "        [0.3994],\n",
      "        [0.4014],\n",
      "        [0.3803],\n",
      "        [0.3956],\n",
      "        [0.4094],\n",
      "        [0.3964],\n",
      "        [0.4063],\n",
      "        [0.3961],\n",
      "        [0.3831],\n",
      "        [0.3987],\n",
      "        [0.3913],\n",
      "        [0.4004],\n",
      "        [0.3852],\n",
      "        [0.4008],\n",
      "        [0.3814],\n",
      "        [0.4094],\n",
      "        [0.4103],\n",
      "        [0.4123],\n",
      "        [0.4009],\n",
      "        [0.4097],\n",
      "        [0.4013],\n",
      "        [0.4099],\n",
      "        [0.3931],\n",
      "        [0.3796],\n",
      "        [0.4026],\n",
      "        [0.3934],\n",
      "        [0.3941],\n",
      "        [0.3822],\n",
      "        [0.4108],\n",
      "        [0.3999],\n",
      "        [0.3907],\n",
      "        [0.3755],\n",
      "        [0.3790],\n",
      "        [0.3916],\n",
      "        [0.4053],\n",
      "        [0.3866],\n",
      "        [0.3997],\n",
      "        [0.4019],\n",
      "        [0.4071],\n",
      "        [0.3983],\n",
      "        [0.4123],\n",
      "        [0.3984],\n",
      "        [0.3970],\n",
      "        [0.3881],\n",
      "        [0.3784],\n",
      "        [0.3729],\n",
      "        [0.3818],\n",
      "        [0.3785],\n",
      "        [0.3843],\n",
      "        [0.3820],\n",
      "        [0.3882],\n",
      "        [0.3816],\n",
      "        [0.3987],\n",
      "        [0.3922],\n",
      "        [0.4013],\n",
      "        [0.3919],\n",
      "        [0.4015],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3929],\n",
      "        [0.4024],\n",
      "        [0.4102],\n",
      "        [0.3699],\n",
      "        [0.3796],\n",
      "        [0.4059],\n",
      "        [0.4006],\n",
      "        [0.3702],\n",
      "        [0.3874],\n",
      "        [0.3768],\n",
      "        [0.3996],\n",
      "        [0.3927],\n",
      "        [0.3963],\n",
      "        [0.3941],\n",
      "        [0.3857],\n",
      "        [0.3976],\n",
      "        [0.4002],\n",
      "        [0.4044],\n",
      "        [0.3993],\n",
      "        [0.3728],\n",
      "        [0.4102],\n",
      "        [0.3845],\n",
      "        [0.3814],\n",
      "        [0.3979],\n",
      "        [0.3975],\n",
      "        [0.4122],\n",
      "        [0.3703],\n",
      "        [0.4038],\n",
      "        [0.3733],\n",
      "        [0.3831],\n",
      "        [0.3699],\n",
      "        [0.3764],\n",
      "        [0.3817],\n",
      "        [0.3927],\n",
      "        [0.3753],\n",
      "        [0.4105],\n",
      "        [0.3824],\n",
      "        [0.3811],\n",
      "        [0.4023],\n",
      "        [0.3905],\n",
      "        [0.3971],\n",
      "        [0.3808],\n",
      "        [0.3858],\n",
      "        [0.3782],\n",
      "        [0.4005],\n",
      "        [0.3714],\n",
      "        [0.3835],\n",
      "        [0.3991],\n",
      "        [0.3752],\n",
      "        [0.3809],\n",
      "        [0.4085],\n",
      "        [0.3997],\n",
      "        [0.3798],\n",
      "        [0.4073],\n",
      "        [0.3958],\n",
      "        [0.3735],\n",
      "        [0.3741],\n",
      "        [0.3871],\n",
      "        [0.3931],\n",
      "        [0.3979],\n",
      "        [0.4058],\n",
      "        [0.3792],\n",
      "        [0.3953],\n",
      "        [0.3728],\n",
      "        [0.3789],\n",
      "        [0.3925],\n",
      "        [0.3956],\n",
      "        [0.4023],\n",
      "        [0.3779],\n",
      "        [0.3941],\n",
      "        [0.4043],\n",
      "        [0.3738],\n",
      "        [0.4078],\n",
      "        [0.3814],\n",
      "        [0.3799],\n",
      "        [0.4037],\n",
      "        [0.3762],\n",
      "        [0.3819],\n",
      "        [0.3695],\n",
      "        [0.3766],\n",
      "        [0.3731],\n",
      "        [0.3986],\n",
      "        [0.3811],\n",
      "        [0.3978],\n",
      "        [0.4017],\n",
      "        [0.3973],\n",
      "        [0.4125],\n",
      "        [0.3786],\n",
      "        [0.3945],\n",
      "        [0.3987],\n",
      "        [0.3902],\n",
      "        [0.3930],\n",
      "        [0.3988],\n",
      "        [0.3971],\n",
      "        [0.4130],\n",
      "        [0.4077],\n",
      "        [0.3980],\n",
      "        [0.3802],\n",
      "        [0.3709],\n",
      "        [0.3944],\n",
      "        [0.3948],\n",
      "        [0.3777],\n",
      "        [0.4115],\n",
      "        [0.4115],\n",
      "        [0.3955],\n",
      "        [0.3928],\n",
      "        [0.4105],\n",
      "        [0.3992],\n",
      "        [0.3753],\n",
      "        [0.3921],\n",
      "        [0.3887],\n",
      "        [0.3851],\n",
      "        [0.3794],\n",
      "        [0.3928],\n",
      "        [0.3815],\n",
      "        [0.4115],\n",
      "        [0.3967],\n",
      "        [0.3709],\n",
      "        [0.4055],\n",
      "        [0.3773],\n",
      "        [0.4080],\n",
      "        [0.4012],\n",
      "        [0.3885],\n",
      "        [0.3907],\n",
      "        [0.3860],\n",
      "        [0.4064],\n",
      "        [0.3938],\n",
      "        [0.4031],\n",
      "        [0.3816],\n",
      "        [0.3965],\n",
      "        [0.4016],\n",
      "        [0.4000],\n",
      "        [0.3718],\n",
      "        [0.3955],\n",
      "        [0.3743],\n",
      "        [0.3757],\n",
      "        [0.3868],\n",
      "        [0.3763],\n",
      "        [0.3910],\n",
      "        [0.4061],\n",
      "        [0.3983],\n",
      "        [0.3692],\n",
      "        [0.3853],\n",
      "        [0.4077],\n",
      "        [0.3732],\n",
      "        [0.4135],\n",
      "        [0.3693],\n",
      "        [0.3953],\n",
      "        [0.4071],\n",
      "        [0.3712],\n",
      "        [0.3831],\n",
      "        [0.3902],\n",
      "        [0.3735],\n",
      "        [0.3950],\n",
      "        [0.4010],\n",
      "        [0.4087],\n",
      "        [0.3854],\n",
      "        [0.3803],\n",
      "        [0.3890],\n",
      "        [0.3984],\n",
      "        [0.4095],\n",
      "        [0.3729],\n",
      "        [0.3988],\n",
      "        [0.3932],\n",
      "        [0.4062],\n",
      "        [0.4048],\n",
      "        [0.4014],\n",
      "        [0.3867],\n",
      "        [0.4025],\n",
      "        [0.3917],\n",
      "        [0.3756],\n",
      "        [0.4031],\n",
      "        [0.4088],\n",
      "        [0.3739],\n",
      "        [0.3995],\n",
      "        [0.4118],\n",
      "        [0.4035],\n",
      "        [0.3756],\n",
      "        [0.3877],\n",
      "        [0.4002],\n",
      "        [0.3912],\n",
      "        [0.3998],\n",
      "        [0.3709],\n",
      "        [0.3927],\n",
      "        [0.4104],\n",
      "        [0.4127],\n",
      "        [0.3749],\n",
      "        [0.4067],\n",
      "        [0.4058],\n",
      "        [0.3857],\n",
      "        [0.3969],\n",
      "        [0.3950],\n",
      "        [0.3837],\n",
      "        [0.3882],\n",
      "        [0.4039],\n",
      "        [0.4043],\n",
      "        [0.4016],\n",
      "        [0.4019],\n",
      "        [0.3957],\n",
      "        [0.3901],\n",
      "        [0.4104],\n",
      "        [0.4110],\n",
      "        [0.4034],\n",
      "        [0.4017],\n",
      "        [0.3776],\n",
      "        [0.3735],\n",
      "        [0.3844],\n",
      "        [0.3918],\n",
      "        [0.4113],\n",
      "        [0.3863],\n",
      "        [0.4072],\n",
      "        [0.3987],\n",
      "        [0.4061],\n",
      "        [0.4092],\n",
      "        [0.4011],\n",
      "        [0.3702],\n",
      "        [0.3907],\n",
      "        [0.3974],\n",
      "        [0.3980],\n",
      "        [0.3807],\n",
      "        [0.3803],\n",
      "        [0.3985],\n",
      "        [0.4071],\n",
      "        [0.3767],\n",
      "        [0.3806],\n",
      "        [0.4039],\n",
      "        [0.3912],\n",
      "        [0.3896],\n",
      "        [0.4023],\n",
      "        [0.4095],\n",
      "        [0.3825],\n",
      "        [0.3809],\n",
      "        [0.3911],\n",
      "        [0.4074],\n",
      "        [0.3845],\n",
      "        [0.4091],\n",
      "        [0.4008],\n",
      "        [0.3907],\n",
      "        [0.4077],\n",
      "        [0.3973],\n",
      "        [0.3851],\n",
      "        [0.3719],\n",
      "        [0.3731],\n",
      "        [0.3825],\n",
      "        [0.3919],\n",
      "        [0.3909],\n",
      "        [0.4105],\n",
      "        [0.3912],\n",
      "        [0.4069],\n",
      "        [0.3895],\n",
      "        [0.3721],\n",
      "        [0.3768],\n",
      "        [0.3829],\n",
      "        [0.4022],\n",
      "        [0.3742],\n",
      "        [0.3732],\n",
      "        [0.3823],\n",
      "        [0.4060],\n",
      "        [0.3782],\n",
      "        [0.4067],\n",
      "        [0.4083],\n",
      "        [0.3958],\n",
      "        [0.3827],\n",
      "        [0.3866],\n",
      "        [0.3847],\n",
      "        [0.4013],\n",
      "        [0.3806],\n",
      "        [0.3874],\n",
      "        [0.4108],\n",
      "        [0.3828],\n",
      "        [0.3880],\n",
      "        [0.3777],\n",
      "        [0.4046],\n",
      "        [0.3916],\n",
      "        [0.3766],\n",
      "        [0.4076],\n",
      "        [0.3766],\n",
      "        [0.4105],\n",
      "        [0.3894],\n",
      "        [0.4087],\n",
      "        [0.3934],\n",
      "        [0.3754],\n",
      "        [0.3988],\n",
      "        [0.3835],\n",
      "        [0.3945],\n",
      "        [0.3909],\n",
      "        [0.4095],\n",
      "        [0.4036],\n",
      "        [0.3754],\n",
      "        [0.4066],\n",
      "        [0.4004],\n",
      "        [0.3865],\n",
      "        [0.3743],\n",
      "        [0.3712],\n",
      "        [0.3821],\n",
      "        [0.3898],\n",
      "        [0.4115],\n",
      "        [0.4055],\n",
      "        [0.4092],\n",
      "        [0.4035],\n",
      "        [0.3758],\n",
      "        [0.3938],\n",
      "        [0.4129],\n",
      "        [0.3693],\n",
      "        [0.3959],\n",
      "        [0.3774],\n",
      "        [0.3998],\n",
      "        [0.3894],\n",
      "        [0.3974],\n",
      "        [0.3795],\n",
      "        [0.3736],\n",
      "        [0.3697],\n",
      "        [0.3758],\n",
      "        [0.3880],\n",
      "        [0.4133],\n",
      "        [0.3726],\n",
      "        [0.4014],\n",
      "        [0.3779],\n",
      "        [0.3745],\n",
      "        [0.4090],\n",
      "        [0.3875],\n",
      "        [0.3723],\n",
      "        [0.3713],\n",
      "        [0.3998],\n",
      "        [0.3844],\n",
      "        [0.3839],\n",
      "        [0.3928],\n",
      "        [0.4057],\n",
      "        [0.4060],\n",
      "        [0.3911],\n",
      "        [0.3895],\n",
      "        [0.3993],\n",
      "        [0.3862],\n",
      "        [0.4053],\n",
      "        [0.3783],\n",
      "        [0.4118],\n",
      "        [0.4065],\n",
      "        [0.3815],\n",
      "        [0.3906],\n",
      "        [0.4085],\n",
      "        [0.3979],\n",
      "        [0.3970],\n",
      "        [0.4000],\n",
      "        [0.3875],\n",
      "        [0.3958],\n",
      "        [0.4056],\n",
      "        [0.3964],\n",
      "        [0.3927],\n",
      "        [0.3873],\n",
      "        [0.4056],\n",
      "        [0.4037],\n",
      "        [0.3796],\n",
      "        [0.3828],\n",
      "        [0.3828],\n",
      "        [0.4049],\n",
      "        [0.3852],\n",
      "        [0.3939],\n",
      "        [0.4094],\n",
      "        [0.3904],\n",
      "        [0.3969],\n",
      "        [0.3767],\n",
      "        [0.4086],\n",
      "        [0.3889],\n",
      "        [0.3992],\n",
      "        [0.3861],\n",
      "        [0.3912],\n",
      "        [0.3954],\n",
      "        [0.4043],\n",
      "        [0.4094],\n",
      "        [0.4077],\n",
      "        [0.3713],\n",
      "        [0.4111],\n",
      "        [0.3915],\n",
      "        [0.4052],\n",
      "        [0.4063],\n",
      "        [0.4018],\n",
      "        [0.3818],\n",
      "        [0.3960],\n",
      "        [0.3836],\n",
      "        [0.3941],\n",
      "        [0.4080],\n",
      "        [0.3908],\n",
      "        [0.3913],\n",
      "        [0.3715],\n",
      "        [0.4000],\n",
      "        [0.4079],\n",
      "        [0.3800],\n",
      "        [0.3872],\n",
      "        [0.4027],\n",
      "        [0.3876],\n",
      "        [0.4109],\n",
      "        [0.3758],\n",
      "        [0.3900],\n",
      "        [0.3907],\n",
      "        [0.3876],\n",
      "        [0.4080],\n",
      "        [0.3897],\n",
      "        [0.3865],\n",
      "        [0.3788],\n",
      "        [0.3933],\n",
      "        [0.3823],\n",
      "        [0.4103],\n",
      "        [0.3756],\n",
      "        [0.3796],\n",
      "        [0.3838],\n",
      "        [0.3791],\n",
      "        [0.4109],\n",
      "        [0.3950],\n",
      "        [0.3834],\n",
      "        [0.4014],\n",
      "        [0.3712],\n",
      "        [0.3795],\n",
      "        [0.4098],\n",
      "        [0.4119],\n",
      "        [0.3857],\n",
      "        [0.4009],\n",
      "        [0.3865],\n",
      "        [0.3750],\n",
      "        [0.3777],\n",
      "        [0.3824],\n",
      "        [0.3910],\n",
      "        [0.3821],\n",
      "        [0.3912],\n",
      "        [0.3877],\n",
      "        [0.3823],\n",
      "        [0.4071],\n",
      "        [0.3998],\n",
      "        [0.3839],\n",
      "        [0.4044],\n",
      "        [0.4102],\n",
      "        [0.3857],\n",
      "        [0.3720],\n",
      "        [0.3964],\n",
      "        [0.4080],\n",
      "        [0.3876],\n",
      "        [0.3793],\n",
      "        [0.3957],\n",
      "        [0.4098],\n",
      "        [0.4059],\n",
      "        [0.3833],\n",
      "        [0.3774],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3765],\n",
      "        [0.4023],\n",
      "        [0.3813],\n",
      "        [0.4114],\n",
      "        [0.3726],\n",
      "        [0.3869],\n",
      "        [0.4054],\n",
      "        [0.3766],\n",
      "        [0.4071],\n",
      "        [0.4100],\n",
      "        [0.4099],\n",
      "        [0.3958],\n",
      "        [0.3850],\n",
      "        [0.3988],\n",
      "        [0.3800],\n",
      "        [0.4002],\n",
      "        [0.4057],\n",
      "        [0.3840],\n",
      "        [0.3707],\n",
      "        [0.3938],\n",
      "        [0.3922],\n",
      "        [0.3705],\n",
      "        [0.3940],\n",
      "        [0.3850],\n",
      "        [0.3812],\n",
      "        [0.4080],\n",
      "        [0.4065],\n",
      "        [0.3980],\n",
      "        [0.3911],\n",
      "        [0.3970],\n",
      "        [0.3771],\n",
      "        [0.3713],\n",
      "        [0.3905],\n",
      "        [0.3821],\n",
      "        [0.4115],\n",
      "        [0.4126],\n",
      "        [0.3992],\n",
      "        [0.3799],\n",
      "        [0.3895],\n",
      "        [0.4024],\n",
      "        [0.3813],\n",
      "        [0.3747],\n",
      "        [0.3857],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.3887],\n",
      "        [0.4026],\n",
      "        [0.3971],\n",
      "        [0.3888],\n",
      "        [0.3875],\n",
      "        [0.3906],\n",
      "        [0.3711],\n",
      "        [0.3915],\n",
      "        [0.4030],\n",
      "        [0.4088],\n",
      "        [0.4094],\n",
      "        [0.4031],\n",
      "        [0.3730],\n",
      "        [0.3835],\n",
      "        [0.4101],\n",
      "        [0.3857],\n",
      "        [0.3715],\n",
      "        [0.3940],\n",
      "        [0.3756],\n",
      "        [0.4043],\n",
      "        [0.3829],\n",
      "        [0.3990],\n",
      "        [0.3889],\n",
      "        [0.4110],\n",
      "        [0.3879],\n",
      "        [0.3696],\n",
      "        [0.3994],\n",
      "        [0.3907],\n",
      "        [0.4030],\n",
      "        [0.3951],\n",
      "        [0.3816],\n",
      "        [0.3768],\n",
      "        [0.4056],\n",
      "        [0.4008],\n",
      "        [0.3857]])\n",
      "evox: tensor([[1.0000, 0.6525, 1.0000,  ..., 0.7401, 1.0000, 0.7330],\n",
      "        [1.0000, 0.6544, 1.0000,  ..., 0.7429, 1.0000, 0.7357],\n",
      "        [1.0000, 0.6585, 1.0000,  ..., 0.7489, 1.0000, 0.7413],\n",
      "        ...,\n",
      "        [1.0000, 0.6565, 1.0000,  ..., 0.7460, 1.0000, 0.7386],\n",
      "        [1.0000, 0.6544, 1.0000,  ..., 0.7429, 1.0000, 0.7357],\n",
      "        [1.0000, 0.6477, 1.0000,  ..., 0.7332, 1.0000, 0.7265]])\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "loss_progress = np.empty(shape=(0,)) \n",
    "num_bad_epochs = 0\n",
    "\n",
    "for epoch in range(10000): \n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(\"epoch: {}; bad epochs: {}\".format(epoch, num_bad_epochs))\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    #tqdm shows a progress bar. \n",
    "    for i, sim_E_vox_batch in enumerate(tqdm(trainloader), 0):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        pred_E_vox, pred_adc_prime, pred_adc, pred_sigma, pred_axr = net(sim_E_vox_batch)\n",
    "        \n",
    "        \"\"\"print(sim_E_vox_batch)\n",
    "        print(\"pred_E_vox:\", pred_E_vox)\n",
    "        print(\"pred_adc:\", pred_adc)\n",
    "        print(\"pred_sigma:\", pred_sigma)\n",
    "        print(\"pred_axr:\", pred_axr)\"\"\"\n",
    "\n",
    "        if torch.isnan(pred_E_vox).any():\n",
    "            print(\"evox nan found\")\n",
    "        if torch.isnan(pred_adc).any():\n",
    "            print(\"pred_adc nan found\")\n",
    "        if torch.isnan(pred_axr).any():\n",
    "            print(\"pred_axr nan found\")\n",
    "        if torch.isnan(pred_sigma).any():\n",
    "            print(\"sigpred_sigma nan found\")\n",
    "            \n",
    "        #sim_E_vox_batch32 = sim_E_vox_batch.to(torch.float32)\n",
    "        #needed so that loss comparison works\n",
    "        \n",
    "        #print(pred_E_vox)\n",
    "        loss_sig = criterion(pred_E_vox, sim_E_vox_batch)\n",
    "        #loss_prime = criterion(pred_adc_prime,sim_adc_prime)\n",
    "        #loss prime needs sim_adc_prime to be batched. \n",
    "\n",
    "        loss_sig.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss_sig.item()\n",
    "        \n",
    "    print(\"loss: {}\".format(running_loss))\n",
    "    # early stopping\n",
    "    if running_loss < best:\n",
    "        print(\"####################### saving good model #######################\")\n",
    "        final_model = net.state_dict()\n",
    "        best = running_loss\n",
    "        num_bad_epochs = 0\n",
    "        loss_progress = np.append(loss_progress, best)\n",
    "    else:\n",
    "        num_bad_epochs = num_bad_epochs + 1\n",
    "        loss_progress = np.append(loss_progress, best)\n",
    "        if num_bad_epochs == patience:\n",
    "            print(\"done, best loss: {}\".format(best))\n",
    "            break\n",
    "print(\"done\")\n",
    "\n",
    "net.load_state_dict(final_model)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    final_pred_E_vox, final_pred_adc_prime, final_pred_adc_repeated, final_pred_sigma_repeated, final_pred_axr_repeated = net(torch.from_numpy(sim_E_vox.astype(np.float32)))\n",
    "    # adc sigma and axr will have 8 columns which are all the same\n",
    "\n",
    "final_pred_adc = final_pred_adc_repeated[:, 0]\n",
    "final_pred_sigma = final_pred_sigma_repeated [:, 0]\n",
    "final_pred_axr = final_pred_axr_repeated[:, 0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.9795034344578301, 0.0), (-0.1285318295761597, 4.5744437634323794e-05), (0.10425460126037263, 0.000961016572674692)]\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, len(loss_progress) + 1), loss_progress, marker='o', linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "final_pred_E_vox_detached = final_pred_E_vox.detach().numpy()\n",
    "\"\"\"Was having numpy pytorch issues, so this line helps fix it a bit.\"\"\"\n",
    "\n",
    "plt.scatter(be, sim_E_vox[0,:], label='simulated')\n",
    "plt.scatter(be, final_pred_E_vox_detached[0,:], label='predicted')\n",
    "plt.legend()\n",
    "\n",
    "# plot scatter plots to analyse correlation of predicted free params against ground truth\n",
    "plt.figure()\n",
    "\n",
    "param_sim = [sim_adc, sim_sigma, sim_axr]\n",
    "param_pred = [final_pred_adc, final_pred_sigma, final_pred_axr]\n",
    "param_name = ['ADC', 'Sigma', 'AXR']\n",
    "\n",
    "rvals = []\n",
    "\n",
    "for i,_ in enumerate(param_sim):\n",
    "    plt.rcParams['font.size'] = '16'\n",
    "    plt.scatter(param_sim[i], param_pred[i], s=2, c='navy')\n",
    "    plt.xlabel(param_name[i] + ' Ground Truth')\n",
    "    plt.ylabel(param_name[i] + ' Prediction')\n",
    "    rvals.append(scipy.stats.pearsonr(np.squeeze(param_sim[i]), np.squeeze(param_pred[i])))\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "\n",
    "print(rvals)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "530a9f706d6870d645c2a38796218763bd8210a92912827e1b5537d0d478cbf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
